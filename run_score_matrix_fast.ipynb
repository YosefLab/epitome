{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "# from epitome.generators import *\n",
    "from epitome.dataset import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import time\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_runtime(data,\n",
    "                 label_cell_types,  # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix,\n",
    "                 targetmap,\n",
    "                 cellmap,\n",
    "                 radii,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = None,\n",
    "                 indices = None,\n",
    "                 return_feature_names = False,\n",
    "                 **kwargs):\n",
    "    \"\"\"\n",
    "    Takes Deepsea data and calculates distance metrics from cell types whose locations\n",
    "    are specified by label_cell_indices, and the other cell types in the set. Label space is only one cell type.\n",
    "    :param data: dictionary of matrices. Should have keys x and y. x contains n by 1000 rows. y contains n by 919 labels.\n",
    "    :param label_cell_types: list of cell types to be rotated through and used as labels (subset of eval_cell_types)\n",
    "    :param eval_cell_types: list of cell types to be used in evaluation (includes label_cell_types)\n",
    "    :param matrix: matrix of celltype, target positions\n",
    "    :param targetmap: map of column target positions in matrix\n",
    "    :param cellmap: map of row cell type positions in matrix\n",
    "    :param radii: radii to compute similarity distances from\n",
    "    :param similarity_targets: list of targets used to measure cell type similarity (default is DNase-seq)\n",
    "    :param mode: Dataset.TRAIN, VALID, TEST or RUNTIME\n",
    "    :param similarity_matrix: matrix with shape (len(similarity_targets), genome_size) containing binary 0/1s of peaks for similarity_targets\n",
    "    to be compared in the CASV.\n",
    "    :param indices: indices in genome to generate records for.\n",
    "    :param return_feature_names: boolean whether to return string names of features\n",
    "    :param kwargs: kargs\n",
    "\n",
    "    :returns: generator of data with three elements:\n",
    "        1. record features\n",
    "        2. record labels for a given cell type\n",
    "        3. 0/1 mask of labels that have validation data. For example, if this record is for celltype A549,\n",
    "        and A549 does not have data for ATF3, there will be a 0 in the position corresponding to the label space.\n",
    "    \"\"\"\n",
    "\n",
    "    if similarity_matrix is not None:\n",
    "        if len(similarity_matrix.shape) == 1:\n",
    "            similarity_matrix = similarity_matrix[None,:]\n",
    "\n",
    "    if type(similarity_targets) is not list:\n",
    "        similarity_targets = [similarity_targets]\n",
    "\n",
    "    if len(similarity_targets) == 0 and len(radii) > 0:\n",
    "        raise ValueError(\"Cannot set radii to anything if there are no similarity assays, but found len(radii)=%i\" % len(radii))\n",
    "\n",
    "    # get indices for features. rows are cells and cols are targets\n",
    "    cellmap_idx = [cellmap[c] for c in list(eval_cell_types)]\n",
    "    feature_cell_indices = matrix[cellmap_idx,:]\n",
    "\n",
    "    # indices to be deleted. used for similarity comparison, not predictions.\n",
    "    delete_indices = np.array([targetmap[s] for s in similarity_targets]).astype(int)\n",
    "\n",
    "    # make sure no similarity comparison data is missing for all cell types\n",
    "    assert np.invert(np.any(feature_cell_indices[:,delete_indices] == -1)), \\\n",
    "        \"missing data for similarity target at %s\" % (np.where(feature_cell_indices[:,delete_indices] == -1)[0])\n",
    "\n",
    "    # names of labels that are being predicted\n",
    "    feature_targets = [a for a in list(targetmap)] # targets used as features for each evaluation cell type\n",
    "    label_targets = [a for a in feature_targets if a not in similarity_targets]\n",
    "\n",
    "    if (not isinstance(mode, Dataset)):\n",
    "        raise ValueError(\"mode is not a Dataset enum\")\n",
    "\n",
    "    if (not isinstance(indices, np.ndarray) and not isinstance(indices, list)):\n",
    "        # model performs better when there are less 0s\n",
    "        if mode == Dataset.TRAIN:\n",
    "            feature_indices = np.concatenate(list(map(lambda c: EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, c),\n",
    "                                     list(cellmap))))\n",
    "            feature_indices = feature_indices[feature_indices != -1]\n",
    "\n",
    "            # need to re-proportion the indices to oversample underrepresented labels\n",
    "            if (len(list(targetmap)) > 2):\n",
    "                # configure y: label matrix of ChIP for all targets from all cell lines in train\n",
    "                indices = np.concatenate([EpitomeDataset.get_y_indices_for_target(matrix, targetmap, target) for target in label_targets])\n",
    "                indices = indices[indices != -1]\n",
    "                y = data[indices, :].T\n",
    "                m = MLSMOTE(y)\n",
    "                indices = m.fit_resample()\n",
    "\n",
    "            else:\n",
    "                # single TF model\n",
    "                # get indices for DNase and chip for this mark\n",
    "                feature_indices = np.concatenate(list(map(lambda c: EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, c),\n",
    "                                                     list(cellmap))))\n",
    "\n",
    "                # chop off targets being used in similarity metric\n",
    "                not_similarity_indices = np.array([v for k,v in targetmap.items() if k not in similarity_targets])\n",
    "                TF_indices = feature_indices.reshape([len(cellmap),len(targetmap)])[:,not_similarity_indices]\n",
    "\n",
    "                TF_indices =  TF_indices[TF_indices != -1]\n",
    "                feature_indices = feature_indices[feature_indices != -1]\n",
    "\n",
    "                # sites where TF is bound in at least 2 cell line\n",
    "                positive_indices = np.where(np.sum(data[TF_indices,:], axis=0) > 1)[0]\n",
    "                indices_probs = np.ones([data.shape[1]])\n",
    "                indices_probs[positive_indices] = 0\n",
    "                indices_probs = indices_probs/np.sum(indices_probs, keepdims=1)\n",
    "\n",
    "                # If there are nans, it means there were no 0 cases.\n",
    "                # We use this for testing so models converge quickly\n",
    "                # with all ones.\n",
    "                if np.any(np.isnan(indices_probs)):\n",
    "                  print(\"Warning: no negative examples in dataset!!!\")\n",
    "                  indices_probs[:] = 1/indices_probs.shape[0]\n",
    "\n",
    "                # randomly select 10 fold sites where TF is not in any cell line\n",
    "                negative_indices = np.random.choice(np.arange(0,data.shape[1]),\n",
    "                                                    positive_indices.shape[0] * 10,\n",
    "                                                    p=indices_probs)\n",
    "                indices = np.sort(np.concatenate([negative_indices, positive_indices]))\n",
    "\n",
    "        else:\n",
    "            indices = range(0, data.shape[-1]) # not training mode, set to all points\n",
    "\n",
    "    if (mode == Dataset.RUNTIME):\n",
    "        label_cell_types = [\"PLACEHOLDER_CELL\"]\n",
    "        if similarity_matrix is None:\n",
    "            raise Exception(\"similarity_matrix must be defined in runtime mode\")\n",
    "        assert similarity_matrix.shape[0] == len(similarity_targets), \\\n",
    "            \"similarity_matrix is missing data for targets (should have %i rows)\" % (len(similarity_targets))\n",
    "        random_cell = list(cellmap)[0] # placeholder to get label vector length\n",
    "\n",
    "    print(\"using %s as labels for mode %s\" % (label_cell_types, mode))\n",
    "\n",
    "    # string of radii for meta data labeling\n",
    "    radii_str = list(map(lambda x: \"RADII_%i\" % x, radii))\n",
    "\n",
    "    def g():\n",
    "        for i in indices: # for all records specified\n",
    "\n",
    "            for (cell) in label_cell_types: # for all cell types to be used in labels\n",
    "\n",
    "                # labels for this cell\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    label_cell_indices = EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, cell)\n",
    "\n",
    "                    # delete all indices being used in the similarity computation\n",
    "                    label_cell_indices_no_similarities = np.delete(label_cell_indices, delete_indices)\n",
    "\n",
    "                    # Copy target_index_no_similarities and turn into mask of 0/1 for whether data for this cell type for\n",
    "                    # a given label is available.\n",
    "                    target_mask = np.copy(label_cell_indices_no_similarities)\n",
    "                    target_mask[target_mask > -1] = 1\n",
    "                    target_mask[target_mask == -1] = 0\n",
    "\n",
    "                else:\n",
    "                    label_count = len(EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, random_cell))-len(similarity_targets)\n",
    "\n",
    "                    # Mask and labels are all 0's because labels are missing during runtime\n",
    "                    garbage_labels = target_mask = np.zeros(label_count)\n",
    "\n",
    "\n",
    "                # get indices for targets used in similarity computation\n",
    "                # for cell types that are going to be features\n",
    "                similarity_indices = feature_cell_indices[:, delete_indices]\n",
    "\n",
    "\n",
    "                # get indices for each radius in radii\n",
    "                radius_ranges = list(map(lambda x: get_radius_indices(radii, x, i, data.shape[-1]), range(len(radii))))\n",
    "\n",
    "                if len(radius_ranges) > 0:\n",
    "                    radius_indices = np.concatenate(radius_ranges)\n",
    "\n",
    "                    cell_train_data = data[similarity_indices[:,:,None],radius_indices]\n",
    "\n",
    "                    if mode == Dataset.RUNTIME:\n",
    "\n",
    "                        pos = cell_train_data*similarity_matrix[:,radius_indices]\n",
    "#                         agree = cell_train_data == similarity_matrix[:,radius_indices]\n",
    "\n",
    "                    else:\n",
    "                        cell_label_data = data[label_cell_indices[delete_indices][:,None],radius_indices]\n",
    "\n",
    "                        # remove middle dimension and flatten similarity targets\n",
    "                        pos = (cell_train_data*cell_label_data)\n",
    "#                         agree = (cell_train_data == cell_label_data)\n",
    "\n",
    "                    # get indices to split on. remove last because it is empty\n",
    "                    split_indices = np.cumsum([len(i) for i in radius_ranges])[:-1]\n",
    "                    # slice arrays by radii\n",
    "                    pos_arrays = np.split(pos, split_indices, axis= -1 )\n",
    "#                     agree_arrays = np.split(agree, split_indices, axis = -1)\n",
    "\n",
    "                    similarities = np.stack(list(map(lambda x: np.average(x, axis = -1), pos_arrays)),axis=1)\n",
    "                else:\n",
    "                    # no radius, so no similarities. just an empty placeholder\n",
    "                    similarities = np.zeros((len(eval_cell_types),0,0))\n",
    "\n",
    "                # reshape similarities to flatten 1st dimension, which are the targets\n",
    "                # results in the odering:\n",
    "                ## row 1: cell 1: pos for each target and agree for each target for each radius\n",
    "                similarities = similarities.reshape(similarities.shape[0], similarities.shape[1]*similarities.shape[2])\n",
    "\n",
    "                ##### Concatenate all cell type features together ####\n",
    "                final_features = np.concatenate([data[feature_cell_indices,i], similarities],axis=1).flatten()\n",
    "\n",
    "                # mask missing data\n",
    "                f_mask = np.concatenate([feature_cell_indices!=-1,\n",
    "                                         np.ones(similarities.shape)],axis=1).flatten()\n",
    "                final_features = final_features[f_mask != 0]\n",
    "\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    labels = data[label_cell_indices_no_similarities,i]\n",
    "\n",
    "                else: # used when just predicting\n",
    "                    # The features going into the example.\n",
    "                    labels = garbage_labels # all 0's\n",
    "\n",
    "                # append labels and targetmask\n",
    "                final = final_features\n",
    "\n",
    "                #### Finish appending feature labels together ####\n",
    "                # if (return_feature_names):\n",
    "                all_labels = []\n",
    "                feature_names = []\n",
    "                similarity_labels_agreement = ['r%i_%s' % (radius, 'agree') for radius in radii]\n",
    "#                 similarity_labels_dp = ['r%i_%s' % (radius, 'dp') for radius in radii]\n",
    "                similarity_labels = similarity_labels_agreement\n",
    "\n",
    "                # concatenate together feature names\n",
    "                for j,c in enumerate(eval_cell_types):\n",
    "                    tmp = np.array(feature_targets)[feature_cell_indices[j,:] != -1]\n",
    "                    al = ['%s_%s' % (c, a) for a in tmp]\n",
    "                    sl = ['%s_%s' % (c, s) for s in similarity_labels]\n",
    "\n",
    "                    feature_names.append(al)\n",
    "                    feature_names.append(sl)\n",
    "\n",
    "                all_labels.append(np.concatenate(feature_names))\n",
    "                # all_labels.append(['lbl_%s_%s' % (cell, a) for a in label_targets]) # of form lbl_cellline_target\n",
    "                # all_labels.append(['mask_%s_%s' % (cell, a) for a in label_targets]) # of form mask_cellline_target\n",
    "\n",
    "                    # yield (final, tuple(all_labels))\n",
    "                all_labels = all_labels[0]\n",
    "                indx_to_keep = []\n",
    "                for i in range(len(all_labels)):\n",
    "                    for a in similarity_targets:\n",
    "                        # print(a, all_labels[i])\n",
    "                        if a in all_labels[i]:\n",
    "                            \n",
    "                            indx_to_keep.append(final[i])\n",
    "\n",
    "                yield np.array(indx_to_keep)\n",
    "\n",
    "\n",
    "    return g\n",
    "\n",
    "def load_data_no_label_mask(data,\n",
    "                 label_cell_types,  # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix,\n",
    "                 targetmap,\n",
    "                 cellmap,\n",
    "                 radii,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 mode = Dataset.TRAIN,\n",
    "                 similarity_matrix = None,\n",
    "                 indices = None,\n",
    "                 return_feature_names = False,\n",
    "                 **kwargs):\n",
    "    \"\"\"\n",
    "    Takes Deepsea data and calculates distance metrics from cell types whose locations\n",
    "    are specified by label_cell_indices, and the other cell types in the set. Label space is only one cell type.\n",
    "    :param data: dictionary of matrices. Should have keys x and y. x contains n by 1000 rows. y contains n by 919 labels.\n",
    "    :param label_cell_types: list of cell types to be rotated through and used as labels (subset of eval_cell_types)\n",
    "    :param eval_cell_types: list of cell types to be used in evaluation (includes label_cell_types)\n",
    "    :param matrix: matrix of celltype, target positions\n",
    "    :param targetmap: map of column target positions in matrix\n",
    "    :param cellmap: map of row cell type positions in matrix\n",
    "    :param radii: radii to compute similarity distances from\n",
    "    :param similarity_targets: list of targets used to measure cell type similarity (default is DNase-seq)\n",
    "    :param mode: Dataset.TRAIN, VALID, TEST or RUNTIME\n",
    "    :param similarity_matrix: matrix with shape (len(similarity_targets), genome_size) containing binary 0/1s of peaks for similarity_targets\n",
    "    to be compared in the CASV.\n",
    "    :param indices: indices in genome to generate records for.\n",
    "    :param return_feature_names: boolean whether to return string names of features\n",
    "    :param kwargs: kargs\n",
    "\n",
    "    :returns: generator of data with three elements:\n",
    "        1. record features\n",
    "        2. record labels for a given cell type\n",
    "        3. 0/1 mask of labels that have validation data. For example, if this record is for celltype A549,\n",
    "        and A549 does not have data for ATF3, there will be a 0 in the position corresponding to the label space.\n",
    "    \"\"\"\n",
    "\n",
    "    # reshape similarity_matrix to a matrix if there is only one target\n",
    "    if similarity_matrix is not None:\n",
    "        if len(similarity_matrix.shape) == 1:\n",
    "            similarity_matrix = similarity_matrix[None,:]\n",
    "\n",
    "    if type(similarity_targets) is not list:\n",
    "        similarity_targets = [similarity_targets]\n",
    "\n",
    "    if len(similarity_targets) == 0 and len(radii) > 0:\n",
    "        raise ValueError(\"Cannot set radii to anything if there are no similarity assays, but found len(radii)=%i\" % len(radii))\n",
    "\n",
    "    # get indices for features. rows are cells and cols are targets\n",
    "    cellmap_idx = [cellmap[c] for c in list(eval_cell_types)]\n",
    "    feature_cell_indices = matrix[cellmap_idx,:]\n",
    "\n",
    "    # indices to be deleted. used for similarity comparison, not predictions.\n",
    "    delete_indices = np.array([targetmap[s] for s in similarity_targets]).astype(int)\n",
    "\n",
    "    # make sure no similarity comparison data is missing for all cell types\n",
    "    assert np.invert(np.any(feature_cell_indices[:,delete_indices] == -1)), \\\n",
    "        \"missing data for similarity target at %s\" % (np.where(feature_cell_indices[:,delete_indices] == -1)[0])\n",
    "\n",
    "    # names of labels that are being predicted\n",
    "    feature_targets = [a for a in list(targetmap)] # targets used as features for each evaluation cell type\n",
    "    label_targets = [a for a in feature_targets if a not in similarity_targets]\n",
    "\n",
    "    if (not isinstance(mode, Dataset)):\n",
    "        raise ValueError(\"mode is not a Dataset enum\")\n",
    "\n",
    "    if (not isinstance(indices, np.ndarray) and not isinstance(indices, list)):\n",
    "        # model performs better when there are less 0s\n",
    "        if mode == Dataset.TRAIN:\n",
    "            feature_indices = np.concatenate(list(map(lambda c: EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, c),\n",
    "                                     list(cellmap))))\n",
    "            feature_indices = feature_indices[feature_indices != -1]\n",
    "\n",
    "            # need to re-proportion the indices to oversample underrepresented labels\n",
    "            if (len(list(targetmap)) > 2):\n",
    "                # configure y: label matrix of ChIP for all targets from all cell lines in train\n",
    "                indices = np.concatenate([EpitomeDataset.get_y_indices_for_target(matrix, targetmap, target) for target in label_targets])\n",
    "                indices = indices[indices != -1]\n",
    "                y = data[indices, :].T\n",
    "                m = MLSMOTE(y)\n",
    "                indices = m.fit_resample()\n",
    "\n",
    "            else:\n",
    "                # single TF model\n",
    "                # get indices for DNase and chip for this mark\n",
    "                feature_indices = np.concatenate(list(map(lambda c: EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, c),\n",
    "                                                     list(cellmap))))\n",
    "\n",
    "                # chop off targets being used in similarity metric\n",
    "                not_similarity_indices = np.array([v for k,v in targetmap.items() if k not in similarity_targets])\n",
    "                TF_indices = feature_indices.reshape([len(cellmap),len(targetmap)])[:,not_similarity_indices]\n",
    "\n",
    "                TF_indices =  TF_indices[TF_indices != -1]\n",
    "                feature_indices = feature_indices[feature_indices != -1]\n",
    "\n",
    "                # sites where TF is bound in at least 2 cell line\n",
    "                positive_indices = np.where(np.sum(data[TF_indices,:], axis=0) > 1)[0]\n",
    "                indices_probs = np.ones([data.shape[1]])\n",
    "                indices_probs[positive_indices] = 0\n",
    "                indices_probs = indices_probs/np.sum(indices_probs, keepdims=1)\n",
    "\n",
    "                # If there are nans, it means there were no 0 cases.\n",
    "                # We use this for testing so models converge quickly\n",
    "                # with all ones.\n",
    "                if np.any(np.isnan(indices_probs)):\n",
    "                  print(\"Warning: no negative examples in dataset!!!\")\n",
    "                  indices_probs[:] = 1/indices_probs.shape[0]\n",
    "\n",
    "                # randomly select 10 fold sites where TF is not in any cell line\n",
    "                negative_indices = np.random.choice(np.arange(0,data.shape[1]),\n",
    "                                                    positive_indices.shape[0] * 10,\n",
    "                                                    p=indices_probs)\n",
    "                indices = np.sort(np.concatenate([negative_indices, positive_indices]))\n",
    "\n",
    "        else:\n",
    "            indices = range(0, data.shape[-1]) # not training mode, set to all points\n",
    "\n",
    "    if (mode == Dataset.RUNTIME):\n",
    "        label_cell_types = [\"PLACEHOLDER_CELL\"]\n",
    "        if similarity_matrix is None:\n",
    "            raise Exception(\"similarity_matrix must be defined in runtime mode\")\n",
    "        assert similarity_matrix.shape[0] == len(similarity_targets), \\\n",
    "            \"similarity_matrix is missing data for targets (should have %i rows)\" % (len(similarity_targets))\n",
    "        random_cell = list(cellmap)[0] # placeholder to get label vector length\n",
    "\n",
    "    print(\"using %s as labels for mode %s\" % (label_cell_types, mode))\n",
    "\n",
    "    # string of radii for meta data labeling\n",
    "    radii_str = list(map(lambda x: \"RADII_%i\" % x, radii))\n",
    "\n",
    "    def g():\n",
    "        for i in indices: # for all records specified\n",
    "\n",
    "            for (cell) in label_cell_types: # for all cell types to be used in labels\n",
    "\n",
    "                # labels for this cell\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    label_cell_indices = EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, cell)\n",
    "\n",
    "                    # delete all indices being used in the similarity computation\n",
    "                    label_cell_indices_no_similarities = np.delete(label_cell_indices, delete_indices)\n",
    "\n",
    "                    # Copy target_index_no_similarities and turn into mask of 0/1 for whether data for this cell type for\n",
    "                    # a given label is available.\n",
    "                    target_mask = np.copy(label_cell_indices_no_similarities)\n",
    "                    target_mask[target_mask > -1] = 1\n",
    "                    target_mask[target_mask == -1] = 0\n",
    "\n",
    "                else:\n",
    "                    label_count = len(EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, random_cell))-len(similarity_targets)\n",
    "\n",
    "                    # Mask and labels are all 0's because labels are missing during runtime\n",
    "                    garbage_labels = target_mask = np.zeros(label_count)\n",
    "\n",
    "\n",
    "                # get indices for targets used in similarity computation\n",
    "                # for cell types that are going to be features\n",
    "                similarity_indices = feature_cell_indices[:, delete_indices]\n",
    "\n",
    "\n",
    "                # get indices for each radius in radii\n",
    "                radius_ranges = list(map(lambda x: get_radius_indices(radii, x, i, data.shape[-1]), range(len(radii))))\n",
    "\n",
    "                if len(radius_ranges) > 0:\n",
    "                    radius_indices = np.concatenate(radius_ranges)\n",
    "\n",
    "                    cell_train_data = data[similarity_indices[:,:,None],radius_indices]\n",
    "\n",
    "                    if mode == Dataset.RUNTIME:\n",
    "\n",
    "                        pos = cell_train_data*similarity_matrix[:,radius_indices]\n",
    "#                         agree = cell_train_data == similarity_matrix[:,radius_indices]\n",
    "\n",
    "                    else:\n",
    "                        cell_label_data = data[label_cell_indices[delete_indices][:,None],radius_indices]\n",
    "\n",
    "                        # remove middle dimension and flatten similarity targets\n",
    "                        pos = (cell_train_data*cell_label_data)\n",
    "#                         agree = (cell_train_data == cell_label_data)\n",
    "\n",
    "                    # get indices to split on. remove last because it is empty\n",
    "                    split_indices = np.cumsum([len(i) for i in radius_ranges])[:-1]\n",
    "                    # slice arrays by radii\n",
    "                    pos_arrays = np.split(pos, split_indices, axis= -1 )\n",
    "#                     agree_arrays = np.split(agree, split_indices, axis = -1)\n",
    "\n",
    "                    similarities = np.stack(list(map(lambda x: np.average(x, axis = -1), pos_arrays)),axis=1)\n",
    "                else:\n",
    "                    # no radius, so no similarities. just an empty placeholder\n",
    "                    similarities = np.zeros((len(eval_cell_types),0,0))\n",
    "\n",
    "                # reshape similarities to flatten 1st dimension, which are the targets\n",
    "                # results in the odering:\n",
    "                ## row 1: cell 1: pos for each target and agree for each target for each radius\n",
    "                similarities = similarities.reshape(similarities.shape[0], similarities.shape[1]*similarities.shape[2])\n",
    "\n",
    "                ##### Concatenate all cell type features together ####\n",
    "                final_features = np.concatenate([data[feature_cell_indices,i], similarities],axis=1).flatten()\n",
    "\n",
    "                # mask missing data\n",
    "                f_mask = np.concatenate([feature_cell_indices!=-1,\n",
    "                                         np.ones(similarities.shape)],axis=1).flatten()\n",
    "                final_features = final_features[f_mask != 0]\n",
    "\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    labels = data[label_cell_indices_no_similarities,i]\n",
    "\n",
    "                else: # used when just predicting\n",
    "                    # The features going into the example.\n",
    "                    labels = garbage_labels # all 0's\n",
    "\n",
    "                # append labels and targetmask\n",
    "                final = np.array(final_features)\n",
    "\n",
    "                #### Finish appending feature labels together ####\n",
    "                if (return_feature_names):\n",
    "                    all_labels = []\n",
    "                    feature_names = []\n",
    "                    similarity_labels_agreement = ['r%i_%s' % (radius, 'agree') for radius in radii]\n",
    "#                     similarity_labels_dp = ['r%i_%s' % (radius, 'dp') for radius in radii]\n",
    "                    similarity_labels = similarity_labels_agreement\n",
    "\n",
    "                    # concatenate together feature names\n",
    "                    for j,c in enumerate(eval_cell_types):\n",
    "                        tmp = np.array(feature_targets)[feature_cell_indices[j,:] != -1]\n",
    "                        al = ['%s_%s' % (c, a) for a in tmp]\n",
    "                        sl = ['%s_%s' % (c, s) for s in similarity_labels]\n",
    "\n",
    "                        feature_names.append(al)\n",
    "                        feature_names.append(sl)\n",
    "\n",
    "                    all_labels.append(np.concatenate(feature_names))\n",
    "                    all_labels.append(['lbl_%s_%s' % (cell, a) for a in label_targets]) # of form lbl_cellline_target\n",
    "                    all_labels.append(['mask_%s_%s' % (cell, a) for a in label_targets]) # of form mask_cellline_target\n",
    "\n",
    "                    yield (final, tuple(all_labels))\n",
    "                else:\n",
    "                    yield final\n",
    "\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperModel(EpitomeModel):\n",
    "    def score_matrix_fast(self, accessibility_peak_matrix, regions):\n",
    "        \"\"\" Runs predictions on a matrix of accessibility peaks, where columns are samples and\n",
    "        rows are regions from regions_peak_file. rows in accessilibility_peak_matrix should matching\n",
    "\n",
    "        :param numpy.matrix accessilibility_peak_matrix:  of (samples by genomic regions)\n",
    "        :param str regions: either narrowpeak or bed file containing regions to score, OR a pyranges object\n",
    "            with columns [Chomosome, Start, End, idx]. Index matches each genomic region to a row in\n",
    "            accessilibility_peak_matrix. In both cases, number of regions Should\n",
    "            match rows in accessilibility_peak_matrix\n",
    "\n",
    "        :return: 3-dimensional numpy matrix of predictions: sized (samples by regions by ChIP-seq targets)\n",
    "        :rtype: numpy matrix\n",
    "        \"\"\"\n",
    "\n",
    "        conversionObject = RegionConversion(self.dataset.regions, regions)\n",
    "\n",
    "        results = []\n",
    "        # print(accessibility_peak_matrix.shape)\n",
    "        matrix, indices = conversionObject.get_binary_vector(vector = accessibility_peak_matrix[0,:])\n",
    "        gen = load_data_runtime(data=self.dataset.get_data(Dataset.ALL),\n",
    "                 label_cell_types=self.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types=self.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix=self.dataset.matrix,\n",
    "                 targetmap=self.dataset.targetmap,\n",
    "                 cellmap=self.dataset.cellmap,\n",
    "                 radii = self.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = matrix,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 indices = indices,\n",
    "                 return_feature_names=False)\n",
    "\n",
    "        to_stack = load_data_no_label_mask(data=self.dataset.get_data(Dataset.ALL),\n",
    "                 label_cell_types=self.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types=self.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix=self.dataset.matrix,\n",
    "                 targetmap=self.dataset.targetmap,\n",
    "                 cellmap=self.dataset.cellmap,\n",
    "                 radii = self.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = matrix,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 indices = indices,\n",
    "                 return_feature_names=True)\n",
    "\n",
    "        gen_to_list = list(gen())\n",
    "        to_stack = list(to_stack())\n",
    "        gen_to_list = np.array(gen_to_list)\n",
    "\n",
    "        # reshape to n_regions [from regions] x nassays [acc dim 1] x n_samples\n",
    "        radii = self.radii\n",
    "\n",
    "        stacked = np.stack([to_stack] * accessibility_peak_matrix.shape[0], axis=0)\n",
    "        names = stacked[:, :, 1]\n",
    "        to_stack = stacked[:, :, 0]\n",
    "        to_stack = np.expand_dims(to_stack, axis=-1)\n",
    "\n",
    "        same_size = accessibility_peak_matrix.shape[1] == len(conversionObject.joined.idx_base)\n",
    "\n",
    "        if not same_size:\n",
    "            added_indices = []\n",
    "            old_idx, counter, old_i = 0, 0, 0\n",
    "            indices_to_merge = []\n",
    "            for ctr, (i, i_base) in enumerate(zip(conversionObject.joined.idx, conversionObject.joined.idx_base)):\n",
    "                if i_base == -1:\n",
    "                    continue\n",
    "                if i != old_i:\n",
    "                    indices_to_merge.append((old_idx, counter))\n",
    "                    old_idx = counter\n",
    "                added_indices.append(accessibility_peak_matrix[:, i])\n",
    "                counter += 1\n",
    "                old_i = i\n",
    "            indices_to_merge.append((old_idx, len(conversionObject.joined.idx)))\n",
    "            \n",
    "            a = np.stack(added_indices)\n",
    "        else:\n",
    "            a = np.transpose(accessibility_peak_matrix, axes=[1, 0])\n",
    "        \n",
    "        a = a[:, None, :]\n",
    "        \n",
    "        out = compute_casv(gen_to_list, a, radii)\n",
    "\n",
    "        casv_len = out.shape[1]\n",
    "        num_cells = out.shape[3]\n",
    "        num_regions = out.shape[0]\n",
    "        num_celltypes = out.shape[2]\n",
    "        num_targets = len(self.dataset.targets) if 'DNase' in self.dataset.targets else len(self.dataset.targets) + 1\n",
    "        total_targets = num_targets\n",
    "        \n",
    "        print('CALCULATED CASV')\n",
    "\n",
    "        def first_substring(strings, substring, other, other2):\n",
    "#             return next(i for i, string in enumerate(strings) if substring in string)\n",
    "            for i, s in enumerate(strings):\n",
    "                if substring in s:\n",
    "                      return i\n",
    "            print(strings)\n",
    "            print(substring)\n",
    "            print(other)\n",
    "            print(other2)\n",
    "            return None\n",
    "\n",
    "        for region in tqdm(range(num_regions)):\n",
    "            for cell in range(num_cells):\n",
    "\n",
    "                selected_gen = to_stack[cell, region, :]\n",
    "                naming_scheme = names[cell, region][0]\n",
    "                selected_casv = out[region, :, :, cell]\n",
    "\n",
    "                len_feats_per_celltype = int(selected_gen[0].shape[0] / num_celltypes) # 24 / 2 = 12\n",
    "\n",
    "                old_sg = selected_gen\n",
    "                \n",
    "\n",
    "                for celltype in range(num_celltypes):\n",
    "                    idx = (num_targets + 4) * celltype\n",
    "                    if idx >= len(selected_gen[0]):\n",
    "                        break\n",
    "                    num_targets = first_substring(naming_scheme[idx:idx+len_feats_per_celltype+total_targets], '_agree', naming_scheme[idx-10:idx+len_feats_per_celltype+10], (idx, len_feats_per_celltype))\n",
    "                    casv_cell = selected_casv[:, celltype]\n",
    "                    selected_gen[0][idx + num_targets : idx + num_targets + 4] = casv_cell\n",
    "        \n",
    "        \n",
    "#         set_trace()\n",
    "        print('RUNNING PREDICTIONS')\n",
    "        results = []\n",
    "        for c in tqdm(range(num_cells)):\n",
    "            for r in range(num_regions):\n",
    "                results.append(self._predict(to_stack[c, r, :][0][None, :]))\n",
    "        \n",
    "        results = np.stack(results)\n",
    "        results = results.reshape((to_stack.shape[0], to_stack.shape[1], results.shape[2])) # 4 x 5\n",
    "\n",
    "        if not same_size:\n",
    "            final = []\n",
    "            final = np.empty((accessibility_peak_matrix.shape[0], accessibility_peak_matrix.shape[1], results.shape[2]))\n",
    "            final.fill(np.nan)\n",
    "            for i, tup in enumerate(indices_to_merge):\n",
    "                final[:, i, :] = np.mean(results[:, tup[0]:tup[1], :], axis=1)\n",
    "            \n",
    "            # final = np.stack(final)\n",
    "            # final = final.reshape((accessibility_peak_matrix.shape[0], accessibility_peak_matrix.shape[1], 1))\n",
    "            return final\n",
    "        results = results.reshape((results.shape[0], results.shape[1], total_targets-1))\n",
    "        return results\n",
    "    \n",
    "    def score_matrix(self, accessilibility_peak_matrix, regions):\n",
    "        \"\"\" Runs predictions on a matrix of accessibility peaks, where columns are samples and\n",
    "        rows are regions from regions_peak_file. rows in accessilibility_peak_matrix should matching\n",
    "        :param numpy.matrix accessilibility_peak_matrix:  of (samples by genomic regions)\n",
    "        :param str regions: either narrowpeak or bed file containing regions to score, OR a pyranges object\n",
    "            with columns [Chomosome, Start, End, idx]. Index matches each genomic region to a row in\n",
    "            accessilibility_peak_matrix. In both cases, number of regions Should\n",
    "            match rows in accessilibility_peak_matrix\n",
    "        :return: 3-dimensional numpy matrix of predictions: sized (samples by regions by ChIP-seq targets)\n",
    "        :rtype: numpy matrix\n",
    "        \"\"\"\n",
    "\n",
    "        conversionObject = RegionConversion(self.dataset.regions, regions)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # TODO 9/10/2020: should do something more efficiently than a for loop\n",
    "        for sample_i in tqdm.tqdm(range(accessilibility_peak_matrix.shape[0])):\n",
    "\n",
    "            peaks_i, idx = conversionObject.get_binary_vector(vector = accessilibility_peak_matrix[sample_i,:])\n",
    "\n",
    "            preds = self.eval_vector(peaks_i, idx)\n",
    "\n",
    "            # group preds by joined['idx']\n",
    "            results.append(preds)\n",
    "\n",
    "        # stack all samples along 0th axis\n",
    "        # shape: samples x regions x TFs\n",
    "        tmp = np.stack(results)\n",
    "\n",
    "        # mean and merge along 1st axis\n",
    "        return conversionObject.merge(tmp, axis = 1)\n",
    "\n",
    "def compute_casv(m1, m2, radii, indices= None):\n",
    "    '''\n",
    "    Computes CASV between two matrices. CASV indiciates how similar\n",
    "    two binary matrices are to eachother. m1 and m2 should have the\n",
    "    same number of rows and columns, where rows indicate regions and\n",
    "    columns indicate the assays used to compute the casv (ie DNase-seq, H3K27ac)\n",
    "    :param np.matrix m1: 2D or 3D numpy matrix 2D shape (nregions x (nassays x ncelltypes))\n",
    "      where 2nd dimension is blocked by cells (i.e. cell1assay1, cell1assay2, cell2assay1, cell2assay2)\n",
    "      OR 3D: (nregions x nassays x ncells)\n",
    "    :param np.matrix m2: 3D numpy matrix shape (nregions x nassays x nsamples)\n",
    "    :param radii: list of radii to access surrounding region\n",
    "    :param indices: indices on 0th axis of m1 and m2 to compute casv for\n",
    "    :return numpy matrix of size (len(indices) x CASV dimension x ncelltypes x ncells)\n",
    "    '''\n",
    "\n",
    "    if indices is None:\n",
    "        indices = range(m1.shape[0])\n",
    "\n",
    "    # if only one sample, extend m2 along 2nd axis\n",
    "    if len(m2.shape) == 2:\n",
    "        m2 = m2[:,:,None]\n",
    "\n",
    "    # if needed, reshape m1 to put all assay/train cells on the last axis\n",
    "    if len(m1.shape) == 3:\n",
    "      ncells = m1.shape[-1]\n",
    "      m1 = m1.reshape(m1.shape[0],m1.shape[1]*m1.shape[2])\n",
    "    else:\n",
    "      denom = 1 if m2.shape[1]==0 else m2.shape[1]\n",
    "      ncells = int(m1.shape[-1]/denom)\n",
    "\n",
    "    if m2.shape[1] == 0:\n",
    "      # in this case, there is no CASV to compute, so we just return\n",
    "      return np.zeros((len(indices),0, ncells,m2.shape[-1]))\n",
    "\n",
    "    print(m1.shape, m2.shape)\n",
    "    assert m1.shape[0] == m2.shape[0]\n",
    "    # verify number of assays match\n",
    "    assert m2.shape[1] == m1.shape[-1]/ncells\n",
    "    # print('HERE')\n",
    "    \n",
    "#     set_trace()\n",
    "\n",
    "    def f(i):\n",
    "        \n",
    "#         set_trace()\n",
    "        # get indices for each radius in radii\n",
    "        radius_ranges = list(map(lambda x: get_radius_indices(radii, x, i, m1.shape[0]), range(len(radii))))\n",
    "\n",
    "        if len(radius_ranges) > 0:\n",
    "            radius_indices = np.concatenate(radius_ranges)\n",
    "\n",
    "            # data from known cell types (m1 portion)\n",
    "            m1_slice = m1[radius_indices, :]\n",
    "            m2_slice = np.repeat(m2[radius_indices, :, :],axis=1, repeats = ncells)\n",
    "            \n",
    "\n",
    "            # shape: radius size x (nassaysxncells) by nsamples\n",
    "            pos = (m1_slice.T*m2_slice.T).T\n",
    "#             agree = (m1_slice.T == m2_slice.T).T\n",
    "\n",
    "            # split pos and agree arrays to create new dimension for ncells\n",
    "            # the new dimension will be 4D: (radius x nassays x ncells x nsamples)\n",
    "            pos = np.stack(np.split(pos, ncells, axis=1), axis=2)\n",
    "#             agree = np.stack(np.split(agree, ncells, axis=1), axis=2)\n",
    "            \n",
    "            # get indices to split on. remove last because it is empty\n",
    "            split_indices = np.cumsum([len(i) for i in radius_ranges])[:-1]\n",
    "            # slice arrays by radii\n",
    "            pos_arrays = np.split(pos, split_indices, axis= 0 )\n",
    "#             agree_arrays = np.split(agree, split_indices, axis = 0)\n",
    "\n",
    "            # average over the radius (0th axis)\n",
    "            tmp1 = list(map(lambda x: np.average(x, axis = 0), pos_arrays)) # this line is problematic\n",
    "            # final concatenation combines agree, nassays, and radii on the 0th axis\n",
    "            # this axis is ordered by (1) pos/agree, then (2) radii, then (2) n assays.\n",
    "            # See ordering example when there are 2 radii (r1, r2):\n",
    "            # - pos: r1, nassays | pos: r2, nassays | agree: r1: nassays | agree: r1: nassays\n",
    "            tmp = np.concatenate(tmp1, axis=0)\n",
    "            return tmp\n",
    "        else:\n",
    "            # no radius, so no similarities. just an empty placeholder\n",
    "            # shaped with the number of cells (last dim of m1)\n",
    "            return np.zeros((0,ncells,m2.shape[-1]))\n",
    "\n",
    "    # for every region of interest\n",
    "    # TODO: maybe something more efficient?\n",
    "\n",
    "    # set_trace()\n",
    "    tmp = []\n",
    "    for i in indices:\n",
    "        tmp.append(f(i))\n",
    "    \n",
    "    return np.stack(tmp)\n",
    "#     return np.stack([f(i) for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_targets = ['SPI1',\n",
    "     'JUNB',\n",
    "     'NR3C1',\n",
    "     'FOSL1',\n",
    "     'FOS',\n",
    "     'FOXP1',\n",
    "     'MEF2B',\n",
    "     'FOXP3',\n",
    "     'NFATC2',\n",
    "     'ETS1',\n",
    "     'STAT3',\n",
    "     'YY1',\n",
    "     'REST',\n",
    "     'NFE2',\n",
    "     'MEIS1',\n",
    "     'EGR1',\n",
    "     'NFKB1',\n",
    "     'IRF2',\n",
    "     'EBF1',\n",
    "     'RELA',\n",
    "     'CEBPB',\n",
    "     'CTCF']\n",
    "\n",
    "# targets mentioned in Satpathy paper\n",
    "satpathy_targets = ['BCL11A',\n",
    "     'CEBPA',\n",
    "     'FOXO1',\n",
    "     'GATA1',\n",
    "     'GATA2',\n",
    "     'HIF1A',\n",
    "     'IRF4',\n",
    "     'JUN',\n",
    "     'KLF4',\n",
    "     'MAFK',\n",
    "     'NFATC1',\n",
    "     'NFIC',\n",
    "     'NFKB1',\n",
    "     'NR3C1',\n",
    "     'NR4A1',\n",
    "     'PAX5',\n",
    "     'PRDM1',\n",
    "     'RARA',\n",
    "     'RBPJ',\n",
    "     'RUNX1',\n",
    "     'SPI1',\n",
    "     'SRF',\n",
    "     'STAT5A',\n",
    "     'TCF3',\n",
    "     'YY1']\n",
    "\n",
    "targets = list(set(np.concatenate([eval_targets, satpathy_targets])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:330: UserWarning: min_targets_per_cell should not be < 2 (this means it only has a similarity target) but was set to 1\n",
      "  warnings.warn(\"min_targets_per_cell should not be < 2 (this means it only has a similarity target) but was set to %i\" % min_targets_per_cell)\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:333: UserWarning: min_cells_per_target should not be < 2 (this means you may only see it in test) but was set to 1\n",
      "  warnings.warn(\"min_cells_per_target should not be < 2 (this means you may only see it in test) but was set to %i\" % min_cells_per_target)\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: EBF1 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: FOXP3 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: IRF2 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: FOXO1 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: NFATC2 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: MEIS1 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n",
      "/home/eecs/rvkoodli/epitome_modified/epitome/dataset.py:422: UserWarning: NFATC1 does not have enough data for cutoffs of min_cells_per_target=3 and min_targets_per_cell=3\n",
      "  (a, min_cells_per_target, min_targets_per_cell))\n"
     ]
    }
   ],
   "source": [
    "# that we have data we can use for validation\n",
    "CHIP_ALTAS_VALIDATION_CELLS = {'Monocytes':'Monocytes',\n",
    "            'Dendritic Cells':'Dendritic_Cells',\n",
    "            'Hematopoietic Stem Cells':'HSC',\n",
    "            'B-Lymphocytes':'B_Cells',\n",
    "            'PBMC':'PBMC',\n",
    "            'CD34+ cells': 'CD34_Progenitors',\n",
    "            'CD4-Positive T-Lymphocytes':'Naive_CD4_T_Cells',#'Memory_CD4_T_Cells']\n",
    "           }\n",
    "\n",
    "dataset = EpitomeDataset(targets = targets,\n",
    "                            cells=None,\n",
    "                           min_cells_per_target = 1,\n",
    "                         min_targets_per_cell = 1)\n",
    "cells = list(dataset.cellmap)\n",
    "[cells.remove(i) for i in CHIP_ALTAS_VALIDATION_CELLS.keys() if i in cells]\n",
    "\n",
    "dataset = EpitomeDataset(targets = targets,\n",
    "                        cells=cells,\n",
    "                       min_cells_per_target = 3,\n",
    "                     min_targets_per_cell = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 133962)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"EPITOME_DATA_PATH\"] = '/data/yosef2/users/akmorrow/data/scEpitome_data/CHIPATLAS/hg19'\n",
    "\n",
    "# paths to Tal's dataset\n",
    "DATA_PATH='/data/yosef/users/tal_ashuach/PeakVI/Datasets/Satpathy'\n",
    "regions_peak_file = os.path.join(DATA_PATH, 'rds_f_regions.tsv')\n",
    "cluster_file = os.path.join(DATA_PATH, 'rds_f_cells.tsv')\n",
    "\n",
    "regions_peak_file = os.path.join(DATA_PATH, 'rds_f_regions.tsv')\n",
    "\n",
    "\n",
    "# load in matrix\n",
    "accessilibility_peak_matrix = np.load(os.path.join(DATA_PATH, 'imputed.npy'))\n",
    "\n",
    "# load in regions and filter by regions we are actually scoring\n",
    "regions = bed2Pyranges(regions_peak_file ).df\n",
    "regions.sort_values(by='idx', inplace=True)\n",
    "\n",
    "# load in cluster labels\n",
    "clusters = pd.read_csv(cluster_file, sep='\\t')\n",
    "# group by clusters and get cell indices in each cluster\n",
    "split_indices = clusters.groupby('CellType').indices\n",
    "cluster_keys = list(split_indices.keys())\n",
    "cluster_indices = list(split_indices.values())\n",
    "\n",
    "# mean cells by clusters\n",
    "means = [np.mean(accessilibility_peak_matrix[ind,:], axis=0) for ind in cluster_indices]\n",
    "means_matrix = np.vstack(means)\n",
    "\n",
    "means_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['iPS cells', 'hESC derived neural cells', 'hESC derived mesendodermal cells', 'hESC H9', 'hESC H1', 'Unclassified', 'U2OS', 'U-937', 'Treg', 'Testis', 'T-47D', 'SW 480', 'SKH1', 'SK-N-SH', 'RS4-11', 'PC-3', 'PANC-1', 'Osteoblasts', 'OCI-LY-7', 'NB-4', 'NAMALWA', 'Mesenchymal stem cells', 'Macrophages', 'MOLM-13', 'MM.1S', 'MG-63', 'MDA-MB-231', 'MCF-7', 'Lymphoblastoid cell line', 'LoVo', 'LNCAP', 'L-1236', 'Keratinocytes', 'Kasumi-1', 'K-562', 'Jurkat', 'IMR-90', 'HuH-7', 'Hep G2', 'HeLa', 'HUVEC', 'HMEC', 'HL-60', 'HCT 116', 'HAP1', 'GP5d', 'GM12878', 'Fibroblasts', 'Erythroid Cells', 'ECC-1', 'Carcinoma, Renal Cell', 'CD34+', 'BJ', 'Acute myeloid leukemia', 'A549', '786-O', '293'] as labels for mode Dataset.TRAIN\n",
      "using ['iPS cells', 'hESC derived neural cells', 'hESC derived mesendodermal cells', 'hESC H9', 'hESC H1', 'Unclassified', 'U2OS', 'U-937', 'Treg', 'Testis', 'T-47D', 'SW 480', 'SKH1', 'SK-N-SH', 'RS4-11', 'PC-3', 'PANC-1', 'Osteoblasts', 'OCI-LY-7', 'NB-4', 'NAMALWA', 'Mesenchymal stem cells', 'Macrophages', 'MOLM-13', 'MM.1S', 'MG-63', 'MDA-MB-231', 'MCF-7', 'Lymphoblastoid cell line', 'LoVo', 'LNCAP', 'L-1236', 'Keratinocytes', 'Kasumi-1', 'K-562', 'Jurkat', 'IMR-90', 'HuH-7', 'Hep G2', 'HeLa', 'HUVEC', 'HMEC', 'HL-60', 'HCT 116', 'HAP1', 'GP5d', 'GM12878', 'Fibroblasts', 'Erythroid Cells', 'ECC-1', 'Carcinoma, Renal Cell', 'CD34+', 'BJ', 'Acute myeloid leukemia', 'A549', '786-O', '293'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "Batch:  0\n",
      "\tLoss:  6.596838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 5, [])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WrapperModel(dataset)\n",
    "model.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(regions, pd.core.frame.DataFrame):\n",
    "    regions = pr.PyRanges(regions, int64=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8299529,)\n",
      "+--------------+-----------+-----------+-----------+--------------+------------+------------+\n",
      "| Chromosome   | Start     | End       | idx       | Start_base   | End_base   | idx_base   |\n",
      "| (category)   | (int64)   | (int64)   | (int64)   | (int64)      | (int64)    | (int64)    |\n",
      "|--------------+-----------+-----------+-----------+--------------+------------+------------|\n",
      "| chr1         | 10238     | 10738     | 0         | 10200        | 10400      | 3          |\n",
      "| chr1         | 10238     | 10738     | 0         | 10400        | 10600      | 4          |\n",
      "| chr1         | 10238     | 10738     | 0         | 10600        | 10800      | 5          |\n",
      "| chr1         | 237511    | 238011    | 1         | 237400       | 237600     | 657        |\n",
      "| ...          | ...       | ...       | ...       | ...          | ...        | ...        |\n",
      "| chr1         | 249239576 | 249240076 | 13034     | 249239400    | 249239600  | 740999     |\n",
      "| chr1         | 249239576 | 249240076 | 13034     | 249239600    | 249239800  | 741000     |\n",
      "| chr1         | 249239576 | 249240076 | 13034     | 249239800    | 249240000  | 741001     |\n",
      "| chr1         | 249239576 | 249240076 | 13034     | 249240000    | 249240200  | 741002     |\n",
      "+--------------+-----------+-----------+-----------+--------------+------------+------------+\n",
      "Unstranded PyRanges object has 45,400 rows and 7 columns from 1 chromosomes.\n",
      "For printing, the PyRanges was sorted on Chromosome.\n",
      "bv [0. 0. 0. ... 0. 0. 0.]\n",
      "v [0.03948111 0.03948111 0.03948111 ... 0.0285725  0.0285725  0.0285725 ]\n",
      "using ['PLACEHOLDER_CELL'] as labels for mode Dataset.RUNTIME\n",
      "using ['PLACEHOLDER_CELL'] as labels for mode Dataset.RUNTIME\n",
      "(45400, 57) (45400, 1, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/45400 [00:00<02:00, 376.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALCULATED CASV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 45400/45400 [02:01<00:00, 373.11it/s]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING PREDICTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 21/21 [03:48<00:00, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(134)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    132 \u001b[0;31m        \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    133 \u001b[0;31m        \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 134 \u001b[0;31m        \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 4 x 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    135 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msame_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(136)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    134 \u001b[0;31m        \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 4 x 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    135 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 136 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msame_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(137)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    135 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    136 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msame_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 137 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(138)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    136 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msame_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(139)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    137 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  final.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 13035, 36)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  np.mean(results[:, tup[0]:tup[1], :], axis=1).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 36)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  final[:, i, :].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 36)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(141)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m            \u001b[0;31m# final = np.stack(final)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-267-ed8fa0af6cbc>\u001b[0m(140)\u001b[0;36mscore_matrix_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    138 \u001b[0;31m            \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    139 \u001b[0;31m            \u001b[0mfinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 140 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_to_merge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "results = model.score_matrix_fast(means_matrix[:, :13035], regions['chr1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessibility_peak_matrix = means_matrix\n",
    "# regions = pr.PyRanges(regions, int64=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 13035)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_matrix[:, :13035].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------------+-----------+-----------+-----------+\n",
       "| Chromosome   | Start     | End       | idx       |\n",
       "| (category)   | (int64)   | (int64)   | (int64)   |\n",
       "|--------------+-----------+-----------+-----------|\n",
       "| chr1         | 10238     | 10738     | 0         |\n",
       "| chr1         | 237511    | 238011    | 1         |\n",
       "| chr1         | 752456    | 752956    | 2         |\n",
       "| chr1         | 761853    | 762353    | 3         |\n",
       "| ...          | ...       | ...       | ...       |\n",
       "| chr1         | 249201345 | 249201845 | 13031     |\n",
       "| chr1         | 249218817 | 249219317 | 13032     |\n",
       "| chr1         | 249219589 | 249220089 | 13033     |\n",
       "| chr1         | 249239576 | 249240076 | 13034     |\n",
       "+--------------+-----------+-----------+-----------+\n",
       "Unstranded PyRanges object has 13,035 rows and 4 columns from 1 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome."
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions['chr1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error: value_vector must be the same shape as self.compare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-4838bd69bdfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(accessibility_peak_matrix.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversionObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_binary_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccessibility_peak_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m gen = load_data_runtime(data=model.dataset.get_data(Dataset.ALL),\n\u001b[1;32m      7\u001b[0m          \u001b[0mlabel_cell_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_celltypes\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# used for labels. Should be all for train/eval and subset for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epitome_modified/epitome/conversion.py\u001b[0m in \u001b[0;36mget_binary_vector\u001b[0;34m(self, vector)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error: value_vector must be a 1D array\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Error: value_vector must be the same shape as self.compare\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mbase_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Error: value_vector must be the same shape as self.compare"
     ]
    }
   ],
   "source": [
    "conversionObject = RegionConversion(model.dataset.regions, regions['chr1'])\n",
    "\n",
    "results = []\n",
    "# print(accessibility_peak_matrix.shape)\n",
    "matrix, indices = conversionObject.get_binary_vector(vector = accessibility_peak_matrix[0,:])\n",
    "gen = load_data_runtime(data=model.dataset.get_data(Dataset.ALL),\n",
    "         label_cell_types=model.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "         eval_cell_types=model.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "         matrix=model.dataset.matrix,\n",
    "         targetmap=model.dataset.targetmap,\n",
    "         cellmap=model.dataset.cellmap,\n",
    "         radii = model.radii,\n",
    "         mode = Dataset.RUNTIME,\n",
    "         similarity_matrix = matrix,\n",
    "         similarity_targets = ['DNase'],\n",
    "         indices = indices,\n",
    "         return_feature_names=False)\n",
    "\n",
    "gen_to_list = list(gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453764"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gen_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array(gen_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(453764, 57)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8299529,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      3,       4,       5, ..., 8190394, 8190395, 8190396])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.eval_cell_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['PLACEHOLDER_CELL'] as labels for mode Dataset.RUNTIME\n"
     ]
    }
   ],
   "source": [
    "to_stack = load_data_no_label_mask(data=model.dataset.get_data(Dataset.ALL),\n",
    "         label_cell_types=model.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "         eval_cell_types=model.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "         matrix=model.dataset.matrix,\n",
    "         targetmap=model.dataset.targetmap,\n",
    "         cellmap=model.dataset.cellmap,\n",
    "         radii = model.radii,\n",
    "         mode = Dataset.RUNTIME,\n",
    "         similarity_matrix = matrix,\n",
    "         similarity_targets = ['DNase'],\n",
    "         indices = indices,\n",
    "         return_feature_names=False)\n",
    "\n",
    "to_stack = list(to_stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_stacked = np.stack([to_stack] * accessibility_peak_matrix.shape[0], axis=0)\n",
    "names = stacked[:, :, 1]\n",
    "to_stack = stacked[:, :, 0]\n",
    "to_stack = np.expand_dims(to_stack, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 453764, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_stack[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8299529,), (453764,))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape, indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
