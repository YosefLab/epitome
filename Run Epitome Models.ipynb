{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz import *\n",
    "\n",
    "from epitome.constants import *\n",
    "import yaml\n",
    "import subprocess\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\"\n",
    "epitome_data_path = \"data/epitome_data\" \n",
    "feature_path = os.path.join(epitome_data_path, \"feature_name\")\n",
    "TF = \"JUND\"\n",
    "query_cell = 'K562' #'T47D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user directories if they do not exist\n",
    "epitome_results_dir = os.path.join(results_path, \"epitome_results\")\n",
    "if not os.path.exists(epitome_results_dir):\n",
    "    os.makedirs(epitome_results_dir)\n",
    "    \n",
    "tf_epitome_results_dir = os.path.join(epitome_results_dir, TF + \"_results\")\n",
    "if not os.path.exists(tf_epitome_results_dir):\n",
    "    os.makedirs(tf_epitome_results_dir)\n",
    "    \n",
    "model_dir = os.path.join(results_path, \"epitome_models\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "tf_model_dir = os.path.join(model_dir, TF + \"_models\")\n",
    "if not os.path.exists(tf_model_dir):\n",
    "    os.makedirs(tf_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/epitome_data'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epitome_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data for Epitome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'train.npz')).toarray()\n",
    "valid_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'valid.npz')).toarray()\n",
    "test_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'test.npz')).toarray()\n",
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "# all_data = np.concatenate((data[Dataset.TRAIN], data[Dataset.VALID], data[Dataset.TEST]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model with Multiple TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_overlap_tfs = pd.read_csv(\n",
    "    \"/home/eecs/jahnavis/epitome_new/epitome-1/data/epitome_data/Anchor_Epitome_Overlap_TFs.csv\")['TF'].tolist()\n",
    "anchor_tfs = [\"CTCF\", \"E2F1\", \"EGR1\", \"FOXA1\", \"FOXA2\", \"GABPA\", \"HNF4A\", \"JUND\", \n",
    "              \"MAX\", \"NANOG\", \"REST\", \"TAF1\"]\n",
    "# anchor_overlap_tfs = set(epitome_tfs).intersection(set(anchor_tfs))\n",
    "# len(anchor_tfs), len(anchor_overlap_tfs), anchor_overlap_tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = anchor_overlap_tfs,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2)\n",
    "VLP(anchor_overlap_tfs,\n",
    "    data = data,\n",
    "    matrix = matrix,\n",
    "    cellmap = cellmap,\n",
    "    assaymap = assaymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'Ishikawa', 'IMR-90', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'Ishikawa', 'IMR-90', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T47D', 'SK-N-SH', 'MCF-7', 'K562', 'Ishikawa', 'IMR-90', 'HepG2', 'HeLa-S3', 'HCT116', 'H1', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<epitome.models.VLP at 0x7faa1937c630>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFs = [\"CEBPB\", \"CHD2\", \"CTCF\", \"EP300\", \"GABPA\", \"JUND\", \"MAFK\", \"MAX\", \n",
    "       \"MYC\", \"NRF1\", \"RAD21\", \"REST\", \"RFX5\", \"SRF\", \"TAF1\", \"TBP\", \"USF2\"]\n",
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TFs,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2)\n",
    "VLP(TFs,\n",
    "    data = data,\n",
    "    matrix = matrix,\n",
    "    cellmap = cellmap,\n",
    "    assaymap = assaymap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model with Early Stopping (Single TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(40.450397, shape=(), dtype=float32)tf.Tensor(40.44542, shape=(), dtype=float32)tf.Tensor(0.004979495, shape=(), dtype=float32)\n",
      "INFO:tensorflow:0 Validation Generator Time: 213.53789288923144 seconds\n",
      "INFO:tensorflow:0 Validation:tf.Tensor(40.95179, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:1000 tf.Tensor(2.2502952, shape=(), dtype=float32)tf.Tensor(2.2452302, shape=(), dtype=float32)tf.Tensor(0.0050649494, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 Validation Generator Time: 209.84591072797775 seconds\n",
      "INFO:tensorflow:1000 Validation:tf.Tensor(5.357682, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "epitome train: 958.689393\n"
     ]
    }
   ],
   "source": [
    "max_valid_iterations= 1000\n",
    "\n",
    "model = VLP([TF], max_valid_records=max_valid_iterations)\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model.train(2000) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \n",
    "                          \"_no_motif_early_stop_\" + str(max_valid_iterations))\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['transcription_factor', 'query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'transcription_factor' : TF,\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'iterations_trained' : iter_trained,\n",
    "   'train_time': train_time}, \n",
    "    ignore_index=True)\n",
    "\n",
    "eval_results_dir = os.path.join(tf_epitome_results_dir, query_cell + \"_\" + TF + \n",
    "                           '_no_motif_early_stop_'+ str(max_valid_iterations) + \n",
    "                           '.csv')\n",
    "eval_results_df.to_csv(eval_results_dir, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model Without Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "#                                                          eligible_assays = None,\n",
    "#                                                          eligible_cells = None, \n",
    "#                                                          min_cells_per_assay = 2, \n",
    "#                                                          min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'H1', 'A549'] as labels for mode Dataset.VALID\n",
      "WARNING:tensorflow:From /home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/tensorflow_probability/python/layers/util.py:106: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(43.22754, shape=(), dtype=float32)tf.Tensor(43.217567, shape=(), dtype=float32)tf.Tensor(0.009973269, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "epitome train: 136.933354\n"
     ]
    }
   ],
   "source": [
    "TF = \"JUND\"\n",
    "model = VLP([TF])\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model.train(500) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "\n",
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:35,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.9811924769907964\n",
      "INFO:tensorflow:auPRC:     0.020643831303481\n",
      "INFO:tensorflow:GINI:     0.9623849539815926\n",
      "Model auROC: 0.9811924769907964. Model auPRC: 0.020643831303481.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['transcription_factor', 'query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'transcription_factor' : TF,\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'iterations_trained' : iter_trained,\n",
    "   'train_time': train_time}, \n",
    "    ignore_index=True)\n",
    "\n",
    "eval_results_df.to_csv(os.path.join(tf_epitome_results_dir,\n",
    "                                    query_cell + \"_\" + TF + '_no_motif' + '.csv'), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results['preds_mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = \"JUND\"\n",
    "\n",
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = TF,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2)\n",
    "    \n",
    "model2 = VLP([TF],\n",
    "            data = data,\n",
    "            matrix = matrix,\n",
    "            cellmap = cellmap,\n",
    "            assaymap = assaymap)\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model2.train(500) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "\n",
    "model2_results = model2.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_results['preds_mean'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preds_mean': array([[0.12285104, 0.08643743],\n",
       "        [0.12394705, 0.0884769 ],\n",
       "        [0.13021478, 0.08571389],\n",
       "        ...,\n",
       "        [0.2193261 , 0.13365811],\n",
       "        [0.15296759, 0.11804638],\n",
       "        [0.15474007, 0.11731315]], dtype=float32),\n",
       " 'preds_std': array([[0.01769408, 0.0136858 ],\n",
       "        [0.02070205, 0.01198193],\n",
       "        [0.02263527, 0.01317834],\n",
       "        ...,\n",
       "        [0.02264554, 0.0143347 ],\n",
       "        [0.01964175, 0.01462081],\n",
       "        [0.01843329, 0.01442528]], dtype=float32),\n",
       " 'truth': array([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        ...,\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=float32),\n",
       " 'weights': array([[1., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]], dtype=float32),\n",
       " 'assay_dict': {'JUND': {'AUC': 0.9554295876403246,\n",
       "   'auPRC': 0.02699860869218639,\n",
       "   'GINI': 0.8811707786555936},\n",
       "  'JUN': {'AUC': 0.9973328888148025,\n",
       "   'auPRC': 0.058823529411764705,\n",
       "   'GINI': 0.46545285650958207}},\n",
       " 'auROC': 0.9763812382275636,\n",
       " 'auPRC': 0.042911069051975545}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUND_results = os.path.join(tf_epitome_results_dir, \"K562_JUND_motif_anchor.npz\")\n",
    "JUND_preds = np.load(JUND_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JUND_preds['pred'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeNewEnv2",
   "language": "python",
   "name": "epitomenewenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
