{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz import *\n",
    "\n",
    "from epitome.constants import *\n",
    "import yaml\n",
    "import subprocess\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\"\n",
    "epitome_data_path = \"data/epitome_data\" \n",
    "# motif_dir = \"data/motif_data/\"\n",
    "feature_path = os.path.join(epitome_data_path, \"feature_name\")\n",
    "TF = \"EGR1\"\n",
    "query_cell = 'K562' #'T47D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user directories if they do not exist\n",
    "epitome_results_dir = os.path.join(results_path, \"epitome_results\")\n",
    "if not os.path.exists(epitome_results_dir):\n",
    "    os.makedirs(epitome_results_dir)\n",
    "tf_epitome_results_dir = os.path.join(epitome_results_dir, TF + \"_results\")\n",
    "if not os.path.exists(tf_epitome_results_dir):\n",
    "    os.makedirs(tf_epitome_results_dir)\n",
    "model_dir = os.path.join(results_path, \"epitome_models\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "tf_model_dir = os.path.join(model_dir, TF+\"_models\")\n",
    "if not os.path.exists(tf_model_dir):\n",
    "    os.makedirs(tf_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data for Epitome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'train.npz')).toarray()\n",
    "valid_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'valid.npz')).toarray()\n",
    "test_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'test.npz')).toarray()\n",
    "# data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "# all_data = np.concatenate((data[Dataset.TRAIN], data[Dataset.VALID], data[Dataset.TEST]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tfs = [\"CTCF\", \"E2F1\", \"EGR1\", \"FOXA1\", \"FOXA2\", \"GABPA\", \"HNF4A\", \"JUND\", \n",
    "              \"MAX\", \"NANOG\", \"REST\", \"TAF1\"]\n",
    "# anchor_overlap_tfs = set(epitome_tfs).intersection(set(anchor_tfs))\n",
    "# len(anchor_tfs), len(anchor_overlap_tfs), anchor_overlap_tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model With Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = None,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices.shape:  (14839,)\n",
      "indices.shape:  (1000,)\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(49.05606, shape=(), dtype=float32)tf.Tensor(41.69575, shape=(), dtype=float32)tf.Tensor(7.360309, shape=(), dtype=float32)\n",
      "INFO:tensorflow:0 Validation:tf.Tensor(42.204384, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:1000 tf.Tensor(7.1004367, shape=(), dtype=float32)tf.Tensor(1.8727999, shape=(), dtype=float32)tf.Tensor(5.227637, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 Validation:tf.Tensor(12.6759815, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:2000 tf.Tensor(11.200504, shape=(), dtype=float32)tf.Tensor(7.461975, shape=(), dtype=float32)tf.Tensor(3.7385287, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 Validation:tf.Tensor(11.870875, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:3000 tf.Tensor(3.7159553, shape=(), dtype=float32)tf.Tensor(0.8203701, shape=(), dtype=float32)tf.Tensor(2.895585, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 Validation:tf.Tensor(11.624521, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:4000 tf.Tensor(8.840762, shape=(), dtype=float32)tf.Tensor(6.3314962, shape=(), dtype=float32)tf.Tensor(2.5092657, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 Validation:tf.Tensor(11.49618, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "epitome train: 1343.351270\n"
     ]
    }
   ],
   "source": [
    "max_valid_iterations= 1000\n",
    "model = VLP([TF], \n",
    "            max_valid_records=max_valid_iterations)\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model.train(5000) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "model_path = os.path.join(model_dir, query_cell + \"_\" + TF + \"_no_motif_early_stop_\" + str(max_valid_iterations))\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:19,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7816391364420292\n",
      "INFO:tensorflow:auPRC:     0.10222287596374605\n",
      "INFO:tensorflow:GINI:     0.563278282953341\n",
      "Model auROC: 0.7816391364420292. Model auPRC: 0.10222287596374605.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 1), dtype=float32, numpy=\n",
       "array([[0.01288659],\n",
       "       [0.00488806],\n",
       "       [0.00672068],\n",
       "       ...,\n",
       "       [0.00624098],\n",
       "       [0.00804776],\n",
       "       [0.06892596]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results['preds_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['transcription_factor', 'query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'transcription_factor' : TF,\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'iterations_trained' : iter_trained,\n",
    "   'train_time': train_time}, \n",
    "    ignore_index=True)\n",
    "eval_results_df.to_csv(os.path.join(tf_model_dir, query_cell + \"_\" + TF + '_no_motif_early_stop_'+ \n",
    "                                    str(max_valid_iterations) + '.csv'), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model Without Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = None,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(48.95171, shape=(), dtype=float32)tf.Tensor(41.546783, shape=(), dtype=float32)tf.Tensor(7.4049263, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:1000 tf.Tensor(14.521696, shape=(), dtype=float32)tf.Tensor(9.224182, shape=(), dtype=float32)tf.Tensor(5.2975144, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:2000 tf.Tensor(4.7312956, shape=(), dtype=float32)tf.Tensor(0.9051087, shape=(), dtype=float32)tf.Tensor(3.8261867, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:3000 tf.Tensor(3.875723, shape=(), dtype=float32)tf.Tensor(0.91823786, shape=(), dtype=float32)tf.Tensor(2.957485, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:4000 tf.Tensor(3.6272936, shape=(), dtype=float32)tf.Tensor(1.0812979, shape=(), dtype=float32)tf.Tensor(2.5459957, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "epitome train: 754.461974\n"
     ]
    }
   ],
   "source": [
    "model = VLP([TF])\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model.train(5000) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "\n",
    "model_path = os.path.join(model_dir, query_cell + \"_\" + TF +\"_no_motif\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:18,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7775049899549683\n",
      "INFO:tensorflow:auPRC:     0.09626827599994939\n",
      "INFO:tensorflow:GINI:     0.5550099814998234\n",
      "Model auROC: 0.7775049899549683. Model auPRC: 0.09626827599994939.\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['transcription_factor', 'query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'transcription_factor' : TF,\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'iterations_trained' : iter_trained,\n",
    "   'train_time': train_time}, \n",
    "    ignore_index=True)\n",
    "\n",
    "eval_results_df.to_csv(os.path.join(tf_model_dir,\n",
    "                                    query_cell + \"_\" + TF + '_no_motif' + '.csv'), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeNewEnv2",
   "language": "python",
   "name": "epitomenewenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
