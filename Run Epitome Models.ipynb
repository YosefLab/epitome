{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eecs/jahnavis/miniconda/envs/EpitomeNewEnv2/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz import *\n",
    "\n",
    "from epitome.constants import *\n",
    "import yaml\n",
    "import subprocess\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"results\"\n",
    "epitome_data_path = \"data/epitome_data\" \n",
    "feature_path = os.path.join(epitome_data_path, \"feature_name\")\n",
    "TF = \"EGR1\"\n",
    "query_cell = 'K562' #'T47D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create user directories if they do not exist\n",
    "epitome_results_dir = os.path.join(results_path, \"epitome_results\")\n",
    "if not os.path.exists(epitome_results_dir):\n",
    "    os.makedirs(epitome_results_dir)\n",
    "    \n",
    "tf_epitome_results_dir = os.path.join(epitome_results_dir, TF + \"_results\")\n",
    "if not os.path.exists(tf_epitome_results_dir):\n",
    "    os.makedirs(tf_epitome_results_dir)\n",
    "    \n",
    "model_dir = os.path.join(results_path, \"epitome_models\")\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "tf_model_dir = os.path.join(model_dir, TF + \"_models\")\n",
    "if not os.path.exists(tf_model_dir):\n",
    "    os.makedirs(tf_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data for Epitome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'train.npz')).toarray()\n",
    "valid_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'valid.npz')).toarray()\n",
    "test_data = scipy.sparse.load_npz(os.path.join(epitome_data_path, 'test.npz')).toarray()\n",
    "# data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "# all_data = np.concatenate((data[Dataset.TRAIN], data[Dataset.VALID], data[Dataset.TEST]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_tfs = [\"CTCF\", \"E2F1\", \"EGR1\", \"FOXA1\", \"FOXA2\", \"GABPA\", \"HNF4A\", \"JUND\", \n",
    "              \"MAX\", \"NANOG\", \"REST\", \"TAF1\"]\n",
    "# anchor_overlap_tfs = set(epitome_tfs).intersection(set(anchor_tfs))\n",
    "# len(anchor_tfs), len(anchor_overlap_tfs), anchor_overlap_tfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model With Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "                                                         eligible_assays = None,\n",
    "                                                         eligible_cells = None, \n",
    "                                                         min_cells_per_assay = 2, \n",
    "                                                         min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices.shape:  (14839,)\n",
      "indices.shape:  (1000,)\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(53.44295, shape=(), dtype=float32)tf.Tensor(46.102493, shape=(), dtype=float32)tf.Tensor(7.340458, shape=(), dtype=float32)\n",
      "INFO:tensorflow:0 Validation:tf.Tensor(45.60356, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:1000 tf.Tensor(7.273051, shape=(), dtype=float32)tf.Tensor(2.094101, shape=(), dtype=float32)tf.Tensor(5.17895, shape=(), dtype=float32)\n",
      "INFO:tensorflow:1000 Validation:tf.Tensor(14.276231, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:2000 tf.Tensor(4.647738, shape=(), dtype=float32)tf.Tensor(0.9399397, shape=(), dtype=float32)tf.Tensor(3.7077985, shape=(), dtype=float32)\n",
      "INFO:tensorflow:2000 Validation:tf.Tensor(13.186669, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:3000 tf.Tensor(3.7367318, shape=(), dtype=float32)tf.Tensor(0.8658123, shape=(), dtype=float32)tf.Tensor(2.8709195, shape=(), dtype=float32)\n",
      "INFO:tensorflow:3000 Validation:tf.Tensor(12.852262, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:4000 tf.Tensor(3.9606159, shape=(), dtype=float32)tf.Tensor(1.4776208, shape=(), dtype=float32)tf.Tensor(2.482995, shape=(), dtype=float32)\n",
      "INFO:tensorflow:4000 Validation:tf.Tensor(12.695093, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "epitome train: 1694.367276\n"
     ]
    }
   ],
   "source": [
    "max_valid_iterations= 1000\n",
    "\n",
    "model = VLP([TF], max_valid_records=max_valid_iterations)\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model.train(5000) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF + \n",
    "                          \"_no_motif_early_stop_\" + str(max_valid_iterations))\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:26,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7879201303303518\n",
      "INFO:tensorflow:auPRC:     0.10178134574069214\n",
      "INFO:tensorflow:GINI:     0.5758402754996467\n",
      "Model auROC: 0.7879201303303518. Model auPRC: 0.10178134574069214.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['transcription_factor', 'query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'transcription_factor' : TF,\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'iterations_trained' : iter_trained,\n",
    "   'train_time': train_time}, \n",
    "    ignore_index=True)\n",
    "\n",
    "eval_results_dir = os.path.join(tf_epitome_results_dir, query_cell + \"_\" + TF + \n",
    "                           '_no_motif_early_stop_'+ str(max_valid_iterations) + \n",
    "                           '.csv')\n",
    "eval_results_df.to_csv(eval_results_dir, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLP Model Without Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path,\n",
    "#                                                          eligible_assays = None,\n",
    "#                                                          eligible_cells = None, \n",
    "#                                                          min_cells_per_assay = 2, \n",
    "#                                                          min_assays_per_cell= 2) #10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.TRAIN\n",
      "using ['K562', 'H1', 'GM12878'] as labels for mode Dataset.VALID\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:0 tf.Tensor(49.49818, shape=(), dtype=float32)tf.Tensor(42.18291, shape=(), dtype=float32)tf.Tensor(7.3152695, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:1000 tf.Tensor(7.015763, shape=(), dtype=float32)tf.Tensor(1.8432049, shape=(), dtype=float32)tf.Tensor(5.172558, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:2000 tf.Tensor(4.631224, shape=(), dtype=float32)tf.Tensor(0.89494103, shape=(), dtype=float32)tf.Tensor(3.7362833, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:3000 tf.Tensor(4.6076465, shape=(), dtype=float32)tf.Tensor(1.7090476, shape=(), dtype=float32)tf.Tensor(2.898599, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:4000 tf.Tensor(3.3653479, shape=(), dtype=float32)tf.Tensor(0.8576421, shape=(), dtype=float32)tf.Tensor(2.5077057, shape=(), dtype=float32)\n",
      "INFO:tensorflow:\n",
      "epitome train: 951.368395\n"
     ]
    }
   ],
   "source": [
    "model = VLP([TF])\n",
    "\n",
    "start = timer()\n",
    "iter_trained = model.train(5000) # train for 5000 iterations\n",
    "end = timer()\n",
    "train_time = end - start\n",
    "print('epitome train: %f' % train_time)\n",
    "\n",
    "model_path = os.path.join(tf_model_dir, query_cell + \"_\" + TF +\"_no_motif\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:24,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:macro auROC:     0.7928965182650259\n",
      "INFO:tensorflow:auPRC:     0.10307252958579244\n",
      "INFO:tensorflow:GINI:     0.5857930412997123\n",
      "Model auROC: 0.7928965182650259. Model auPRC: 0.10307252958579244.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_results = model.test(10000, calculate_metrics=True)\n",
    "print('Model auROC: %s. Model auPRC: %s.' % (model_results['auROC'], model_results['auPRC'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results_df = pd.DataFrame(columns=['transcription_factor', 'query_cell', 'auROC', 'auPRC'])\n",
    "eval_results_df = eval_results_df.append({ \n",
    "   'transcription_factor' : TF,\n",
    "   'query_cell' : query_cell,\n",
    "   'auROC' : model_results['auROC'],\n",
    "   'auPRC' : model_results['auPRC'],\n",
    "   'iterations_trained' : iter_trained,\n",
    "   'train_time': train_time}, \n",
    "    ignore_index=True)\n",
    "\n",
    "eval_results_df.to_csv(os.path.join(tf_epitome_results_dir,\n",
    "                                    query_cell + \"_\" + TF + '_no_motif' + '.csv'), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeNewEnv2",
   "language": "python",
   "name": "epitomenewenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
