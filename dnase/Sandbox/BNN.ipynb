{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian NN\n",
    "\n",
    "\n",
    "TODOs\n",
    "- then test with curriculum\n",
    "    \n",
    "\n",
    "# Useful Links\n",
    "- cifar ex https://github.com/tensorflow/probability/blob/80cc5cb33dfe04cb998bfe27ad3680a7a116d8b1/tensorflow_probability/examples/cifar10_bnn.py\n",
    "- uses resnet https://github.com/tensorflow/probability/blob/80cc5cb33dfe04cb998bfe27ad3680a7a116d8b1/tensorflow_probability/examples/models/bayesian_resnet.py\n",
    "- http://krasserm.github.io/2019/03/14/bayesian-neural-networks/\n",
    "- https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/bayesian_neural_network.py\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/EpitomeEnv_c76/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "from epitome.constants import *\n",
    "from epitome.models import *\n",
    "from epitome.generators import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "assert(tf.executing_eagerly())\n",
    "import tensorflow_probability as tfp\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(919, 2200000) (919, 4000) (919, 227512)\n"
     ]
    }
   ],
   "source": [
    "# load in user paths\n",
    "# TODO: make a config file with data_path (downloaded from bin/download_deepsea_data.py) \n",
    "# and feature_name_file (at data/feature_name)\n",
    "# My config.yml looks like:\n",
    "# data_path: /data/akmorrow/epitome_data/numpy_data/\n",
    "# feature_name_file: /home/eecs/akmorrow/epitome/data/feature_name\n",
    "\n",
    "with open('/home/eecs/akmorrow/epitome/config.yml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "train_data, valid_data, test_data = load_deepsea_label_data(config[\"data_path\"])\n",
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "print(data[Dataset.TRAIN].shape, data[Dataset.VALID].shape, data[Dataset.TEST].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f32176bc2b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matrix, cellmap, assaymap = get_assays_from_feature_file(eligible_assays = ['DNase','CTCF'],\n",
    "#                                   eligible_cells = None)\n",
    "\n",
    "matrix, cellmap, assaymap = get_assays_from_feature_file(eligible_assays = None,\n",
    "                                  eligible_cells = None, min_cells_per_assay =6, \n",
    "                                                         min_assays_per_cell=7)\n",
    "\n",
    "nv_assaymap = {v: k for k, v in assaymap.items()}\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(np.arange(len(assaymap)), rotation = 90)\n",
    "ax.set_xticklabels(assaymap.keys())\n",
    "plt.yticks(np.arange(len(cellmap)))\n",
    "ax.set_yticklabels(cellmap.keys())\n",
    "\n",
    "plt.imshow(matrix!=Label.UNK.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def load_data(data, \n",
    "#                  label_cell_types,  # used for labels. Should be all for train/eval and subset for test\n",
    "#                  eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "#                  matrix,\n",
    "#                  assaymap,\n",
    "#                  cellmap,\n",
    "#                  radii,\n",
    "#                  **kwargs):\n",
    "    \n",
    "#     # AM 5/20/2019. This is enforcing exclusive DNase bins and will make \n",
    "#     # interpretation of DNase weights easier. It does not add performance benefit\n",
    "#     # over inclusive bins, which was used in the original model.\n",
    "#     exclusive = True\n",
    "\n",
    "#     \"\"\"\n",
    "#     Takes Deepsea data and calculates distance metrics from cell types whose locations\n",
    "#     are specified by label_cell_indices, and the other cell types in the set. Label space is only one cell type.\n",
    "#      TODO AM 3/7/2019\n",
    "#     :param data: dictionary of matrices. Should have keys x and y. x contains n by 1000 rows. y contains n by 919 labels.\n",
    "#     :param label_cell_types: list of cell types to be rotated through and used as labels (subset of eval_cell_types)\n",
    "#     :param eval_cell_types: list of cell types to be used in evaluation (includes label_cell_types)\n",
    "#     :param matrix: matrix of celltype, assay positions\n",
    "#     :param assaymap: map of column assay positions in matrix\n",
    "#     :param cellmap: map of row cell type positions in matrix\n",
    "#     :param radii: radii to compute dnase distances from\n",
    "#     :param kwargs: kargs\n",
    "\n",
    "#     :returns: generator of data with three elements:\n",
    "#         1. record features\n",
    "#         2. record labels for a given cell type\n",
    "#         3. 0/1 mask of labels that have validation data. For example, if this record is for celltype A549,\n",
    "#         and A549 does not have data for ATF3, there will be a 0 in the position corresponding to the label space.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Running in TRAIN, VALID, or TEST?    \n",
    "#     mode = kwargs.get(\"mode\")\n",
    "#     # specifies the indices to generate records.\n",
    "#     # can be used for debug purposes, or to evaluate\n",
    "#     # only specific regions in a vector\n",
    "#     # TODO AM 4/17/2019: move this to an actual parameter\n",
    "#     indices = kwargs.get(\"indices\")\n",
    "    \n",
    "#     if (not isinstance(indices, np.ndarray) and not isinstance(indices, list)):\n",
    "#         indices = range(0, data.shape[-1]) # if not defined, set to all points\n",
    "    \n",
    "#     if (not isinstance(mode, Dataset)):\n",
    "#         raise ValueError(\"mode is not a Dataset enum\")\n",
    "        \n",
    "#     if (mode == Dataset.RUNTIME):\n",
    "#         label_cell_types = [\"PLACEHOLDER_CELL\"]\n",
    "#         dnase_vector = kwargs.get(\"dnase_vector\")\n",
    "#         random_cell = list(cellmap)[0] # placeholder to get label vector length\n",
    "        \n",
    "#     print(\"using %s as labels for mode %s\" % (label_cell_types, mode))\n",
    "    \n",
    "#     # string of radii for meta data labeling\n",
    "#     radii_str = list(map(lambda x: \"DNASE_RADII_%i\" % x, radii))\n",
    "        \n",
    "#     if (mode == Dataset.TEST or mode == Dataset.RUNTIME):\n",
    "#         # Drop cell types with the least information (TODO AM 4/1/2019 this could do something smarter)\n",
    "        \n",
    "#         # make dictionary of eval_cell_type: assay count and sort in decreasing order\n",
    "#         tmp = matrix.copy()\n",
    "#         tmp[tmp>= 0] = 1\n",
    "#         tmp[tmp== -1] = 0\n",
    "#         sums = np.sum(tmp, axis = 1)\n",
    "#         cell_assay_counts = zip(list(cellmap), sums)\n",
    "#         cell_assay_counts = sorted(cell_assay_counts, key = lambda x: x[1])\n",
    "#         # filter by eval_cell_types\n",
    "#         cell_assay_counts = list(filter(lambda x: x[0] in eval_cell_types, cell_assay_counts))\n",
    "        \n",
    "#         # remove cell types with smallest number of factors\n",
    "#         eval_cell_types = eval_cell_types.copy()\n",
    "#         [eval_cell_types.remove(i[0]) for i in cell_assay_counts[0:len(label_cell_types)]]\n",
    "#         del tmp\n",
    "#         del cell_assay_counts\n",
    "        \n",
    "        \n",
    "#     def g():\n",
    "#         for i in indices: # for all records specified\n",
    "#             for (cell) in label_cell_types: # for all cell types to be used in labels\n",
    "#                 dnases = [] \n",
    "#                 dnases_double_positive = []\n",
    "#                 dnases_agreement = []\n",
    "                \n",
    "#                 # cells to be featurized\n",
    "#                 feature_cells = eval_cell_types.copy()\n",
    "                \n",
    "#                 # try to remove cell if it is in the possible list of feature cell types\n",
    "#                 try:\n",
    "#                     feature_cells.remove(cell) \n",
    "#                 except ValueError:\n",
    "#                     pass  # do nothing!\n",
    "                                \n",
    "#                 # features from all remaining cells not in label set\n",
    "#                 feature_cell_indices_list = list(map(lambda c: get_y_indices_for_cell(matrix, cellmap, c), \n",
    "#                                                      feature_cells))\n",
    "#                 feature_cell_indices = np.array(feature_cell_indices_list).flatten()\n",
    "                \n",
    "#                 # labels for this cell\n",
    "#                 if (mode != Dataset.RUNTIME):\n",
    "#                     label_cell_indices = get_y_indices_for_cell(matrix, cellmap, cell)\n",
    "#                     label_cell_indices_no_dnase = np.delete(label_cell_indices, [0])\n",
    "\n",
    "#                     # Copy assay_index_no_dnase and turn into mask of 0/1 for whether data for this cell type for\n",
    "#                     # a given label is available.\n",
    "#                     assay_mask = np.copy(label_cell_indices_no_dnase)\n",
    "#                     assay_mask[assay_mask == -1] = 0\n",
    "#                     assay_mask[assay_mask > 0] = 1\n",
    "                    \n",
    "#                 else:\n",
    "#                     label_count = len(get_y_indices_for_cell(matrix, cellmap, random_cell))-1\n",
    "                    \n",
    "#                     # Mask and labels are all 0's because labels are missing during runtime\n",
    "#                     garbage_labels = assay_mask = np.zeros(label_count)\n",
    "\n",
    "#                 # get dnase indices for cell types that are going to be features\n",
    "#                 dnase_indices = np.array([x[0] for x in feature_cell_indices_list])\n",
    "                \n",
    "#                 for r, radius in enumerate(radii):\n",
    "                    \n",
    "#                     min_radius = max(0, i - radius + 1)\n",
    "#                     max_radius = min(i+radius, data.shape[1])\n",
    "                    \n",
    "#                     # if exclusive == True, then do not featurize chromatin regions\n",
    "#                     # that were considered in smaller radii\n",
    "#                     if (exclusive and r != 0):\n",
    "#                         radius_range_1 = np.arange(min_radius, max(0, i - radii[r-1]+1))\n",
    "#                         radius_range_2 = np.arange(i+radii[r-1], max_radius)\n",
    "                        \n",
    "#                         radius_range = np.concatenate([radius_range_1, radius_range_2])\n",
    "#                     else:\n",
    "                        \n",
    "#                         radius_range = np.arange(min_radius, max_radius)\n",
    "                        \n",
    "                        \n",
    "#                     ####################################################################\n",
    "                    \n",
    "#                     # use DNase vector, if it is provided\n",
    "#                     if (mode == Dataset.RUNTIME):\n",
    "\n",
    "#                         # within the radius, fraction of places where they are both 1\n",
    "#                         dnase_double_positive = np.average(data[dnase_indices[:,None],radius_range]*\n",
    "#                                                  dnase_vector[radius_range], axis=1)\n",
    "\n",
    "#                         # within the radius, fraction of places where they are both equal (0 or 1)\n",
    "#                         dnase_agreement = np.average(data[dnase_indices[:,None],radius_range]==\n",
    "#                                                  dnase_vector[radius_range], axis=1)\n",
    "\n",
    "#                     else:\n",
    "#                         # within the radius, fraction of places where they are both 1\n",
    "#                         # label_cell_index[0] == DNase location for specific cell type\n",
    "#                         dnase_double_positive = np.average(data[dnase_indices[:,None],radius_range]*\n",
    "#                                                  data[label_cell_indices[0],radius_range], axis=1)\n",
    "\n",
    "#                         # within the radius, fraction of places where they are both equal (0 or 1)\n",
    "#                         dnase_agreement = np.average(data[dnase_indices[:,None],radius_range]==\n",
    "#                                                  data[label_cell_indices[0],radius_range], axis=1)\n",
    "                        \n",
    "#                     dnases_double_positive.extend(dnase_double_positive)\n",
    "#                     dnases_agreement.extend(dnase_agreement)\n",
    "                        \n",
    "#                 # rehape agreement DNase to Radii by feature_cells\n",
    "#                 dnases_agreement_reshaped = np.array(dnases_agreement).reshape([len(radii), len(feature_cells)])\n",
    "#                 dnases_double_positive_reshaped = np.array(dnases_double_positive).reshape([len(radii), len(feature_cells)])\n",
    "#                 dnase_means = np.mean(dnases_agreement_reshaped, axis = 0)\n",
    "\n",
    "#                 ######### reorder cells by similarity ################\n",
    "#                 ## This was added 5/30/2019. It seems to *maybe help \n",
    "#                 ## a little bit on cell types not seen in the model.\n",
    "#                 ## This makes sense because cell types are now ordered\n",
    "#                 ## by similarity and keep some spacial positioning \n",
    "#                 ## based on the similarity to the new cell. \n",
    "#                 best_indices = (-dnase_means).argsort()\n",
    "\n",
    "#                 dnases.extend(dnases_double_positive_reshaped[:,best_indices].flatten())\n",
    "#                 dnases.extend(dnases_agreement_reshaped[:,best_indices].flatten())\n",
    "\n",
    "#                 feature_cell_indices = feature_cell_indices.reshape([len(feature_cells), len(assaymap)])[best_indices,:].flatten()\n",
    "#                 ######## End reorder #################################                                                   \n",
    "                                                                        \n",
    "                                                                        \n",
    "#                 # Extract features\n",
    "#                 features = data[feature_cell_indices,i]\n",
    "                \n",
    "#                 # concatenate features and DNases\n",
    "#                 x_data = np.concatenate([features, dnases])\n",
    "                \n",
    "#                 # mask for x_data. 0 = do not mask, 1 = mask.\n",
    "#                 x_mask = np.zeros(x_data.shape[0])\n",
    "#                 x_mask[np.where(feature_cell_indices == -1)[0]] = True # assign mask to missing features\n",
    "\n",
    "#                 # There can be NaNs in the DNases for edge cases (when the radii extends past the end of the chr).\n",
    "#                 # Mask these values in the first row of tmp\n",
    "#                 x_mask[np.where(np.isnan(x_data))[0]] = True # assign mask to missing DNase values\n",
    "#                 x_data[np.where(x_mask == True)[0]] = 0 # set all UNKs to 0\n",
    "                \n",
    "#                 # mask x data by which factors are available for a cell type\n",
    "#                 x_data_masked = np.vstack([x_mask, x_data]) # top row 0 = mask, bottom row 1 = data\n",
    "                        \n",
    "#                 if (mode != Dataset.RUNTIME):\n",
    "#                     labels = data[label_cell_indices_no_dnase,i]\n",
    "\n",
    "#                 else: # used when just predicting\n",
    "#                     # The features going into the example.\n",
    "#                     labels = garbage_labels # all 0's\n",
    "                    \n",
    "#                 yield (x_data_masked, labels, assay_mask)\n",
    "\n",
    "#     return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm \n",
    "\n",
    "# class VariationalPeakModel():\n",
    "#     def __init__(self,\n",
    "#                  data,\n",
    "#                  test_celltypes,\n",
    "#                  matrix,\n",
    "#                  assaymap,\n",
    "#                  cellmap,  \n",
    "#                  debug = False,\n",
    "#                  batch_size=64,\n",
    "#                  shuffle_size=10,\n",
    "#                  prefetch_size=10,\n",
    "#                  l1=0.,\n",
    "#                  l2=0.,\n",
    "#                  lr=1e-3,\n",
    "#                  radii=[1,3,10,30], \n",
    "#                  train_indices = None):\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Peak Model\n",
    "#         :param data: either a path to TF records OR a dictionary of TRAIN, VALID, and TEST data\n",
    "#         :param test_celltypes\n",
    "#         :param matrix\n",
    "#         :param assaymap\n",
    "#         :param cellmap\n",
    "#         :param debug: used to print out intermediate validation values\n",
    "#         :param batch_size\n",
    "#         :param shuffle_size\n",
    "#         :param prefetch_size\n",
    "#         :param l1\n",
    "#         :param l2\n",
    "#         :param lr\n",
    "#         :param radii\n",
    "#         :param train_indices: option numpy array of indices to train from data[Dataset.TRAIN]\n",
    "#         \"\"\"\n",
    "        \n",
    "#         tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "#         assert (set(test_celltypes) < set(list(cellmap))), \\\n",
    "#                 \"test_celltypes %s must be subsets of available cell types %s\" % (str(test_celltypes), str(list(cellmap)))\n",
    "\n",
    "#         # get evaluation cell types by removing any cell types that would be used in test\n",
    "#         self.eval_cell_types = list(cellmap).copy()\n",
    "#         self.test_celltypes = test_celltypes\n",
    "#         [self.eval_cell_types.remove(test_cell) for test_cell in self.test_celltypes]\n",
    "#         print(\"eval cell types\", self.eval_cell_types)\n",
    "\n",
    "#         self.output_shape, self.train_iter = generator_to_tf_dataset(load_data(data[Dataset.TRAIN],  \n",
    "#                                                 self.eval_cell_types,\n",
    "#                                                 self.eval_cell_types,\n",
    "#                                                 matrix,\n",
    "#                                                 assaymap,\n",
    "#                                                 cellmap,\n",
    "#                                                 radii = radii, mode = Dataset.TRAIN),\n",
    "#                                                 batch_size, shuffle_size, prefetch_size)\n",
    "\n",
    "#         _,            self.valid_iter = generator_to_tf_dataset(load_data(data[Dataset.VALID], \n",
    "#                                                 self.eval_cell_types,\n",
    "#                                                 self.eval_cell_types,\n",
    "#                                                 matrix,\n",
    "#                                                 assaymap,\n",
    "#                                                 cellmap,\n",
    "#                                                 radii = radii, mode = Dataset.VALID), \n",
    "#                                                 batch_size, 1, prefetch_size)\n",
    "\n",
    "#         # can be empty if len(test_celltypes) == 0\n",
    "#         _,            self.test_iter = generator_to_tf_dataset(load_data(data[Dataset.TEST], \n",
    "#                                                self.test_celltypes, \n",
    "#                                                self.eval_cell_types,\n",
    "#                                                matrix,\n",
    "#                                                assaymap,\n",
    "#                                                cellmap,\n",
    "#                                                radii = radii, mode = Dataset.TEST),\n",
    "#                                                batch_size, 1, prefetch_size)\n",
    "\n",
    "#         self.num_outputs = self.output_shape[0]\n",
    "#         self.l1, self.l2 = l1, l2\n",
    "#         self.lr = lr\n",
    "#         self.batch_size = batch_size\n",
    "#         self.prefetch_size = prefetch_size\n",
    "#         self.shuffle_size = shuffle_size\n",
    "#         self.optimizer =tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr)\n",
    "\n",
    "#         # set self\n",
    "#         self.model = self.create_model()\n",
    "#         self.radii = radii\n",
    "#         self.debug = debug\n",
    "#         self.assaymap = assaymap\n",
    "#         self.test_celltypes = test_celltypes\n",
    "#         self.matrix = matrix\n",
    "#         self.assaymap= assaymap \n",
    "#         self.cellmap = cellmap\n",
    "#         self.data = data\n",
    "            \n",
    "#     def save(self, checkpoint_path):\n",
    "#         \"\"\"\n",
    "#         Saves model.\n",
    "        \n",
    "#         :param checkpoint_path: string file path to save model to. \n",
    "#         \"\"\"\n",
    "#         # save keras model\n",
    "#         self.model.save(checkpoint_path)\n",
    "        \n",
    "#         # save model params to pickle file\n",
    "#         dict_ = {'test_celltypes':self.test_celltypes,\n",
    "#                          'matrix':self.matrix,\n",
    "#                          'assaymap':self.assaymap,\n",
    "#                          'cellmap':self.cellmap,  \n",
    "#                          'debug': self.debug,\n",
    "#                          'batch_size':self.batch_size,\n",
    "#                          'shuffle_size':self.shuffle_size,\n",
    "#                          'prefetch_size':self.prefetch_size,\n",
    "#                          'radii':self.radii}\n",
    "        \n",
    "#         fileObject = open(os.path.join(checkpoint_path, \"model_params.pickle\"),'wb')\n",
    "#         pickle.dump(dict_,fileObject)   \n",
    "#         fileObject.close()\n",
    "        \n",
    "        \n",
    "#     def gini(self, actual, pred, sample_weight):                                                 \n",
    "#         df = sorted(zip(actual, pred), key=lambda x : (x[1], x[0]),  reverse=True)\n",
    "#         random = [float(i+1)/float(len(df)) for i in range(len(df))]                \n",
    "#         totalPos = np.sum([x[0] for x in df])           \n",
    "#         cumPosFound = np.cumsum([x[0] for x in df])                                     \n",
    "#         Lorentz = [float(x)/totalPos for x in cumPosFound]                          \n",
    "#         Gini = np.array([l - r for l, r in zip(Lorentz, random)])\n",
    "#         # mask Gini with weights\n",
    "#         Gini[np.where(sample_weight == 0)[0]] = 0\n",
    "#         return np.sum(Gini)    \n",
    "\n",
    "#     def gini_normalized(self, actual, pred, sample_weight = None):              \n",
    "#         normalized_gini = self.gini(actual, pred, sample_weight)/self.gini(actual, actual, sample_weight)      \n",
    "#         return normalized_gini       \n",
    "\n",
    "#     def body_fn(self):\n",
    "#         raise NotImplementedError()\n",
    "        \n",
    "#     def g(self, p, a=1, B=0, y=1):\n",
    "#         \"\"\" Normalization Function. Normalizes loss w.r.t. label proportion.\n",
    "\n",
    "#         Constraints: \n",
    "#          1. g(p) = 1 when p = 1\n",
    "#          2. g(p) = a * p^y + B, where a, y and B are hyperparameters\n",
    "#         \"\"\"\n",
    "#         return a * tf.math.pow(p, y) + B\n",
    "    \n",
    "#     def loss_fn(self, y_true, y_pred, weights):\n",
    "#         # weighted sum of cross entropy for non 0 weights\n",
    "#         # Reduction method = Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    "#         loss = tf.compat.v1.losses.sigmoid_cross_entropy(y_true,  \n",
    "#                                                         y_pred[:, Features.FEATURE_IDX.value, :], \n",
    "#                                                         weights = weights,\n",
    "#                                                         reduction = tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "\n",
    "#         C = (len(self.assaymap)-1)\n",
    "#         # p = tf.math.reduce_sum(weights, axis=1)/C # should be of dimension 1 by batch size\n",
    "#         p = 1.0 # this is just taking the mean loss, nothing special here.\n",
    "#         return self.g(p)/C * loss\n",
    "    \n",
    "    \n",
    "#     def train(self, num_steps, lr=None, checkpoint_path = None):\n",
    "#         if lr == None:\n",
    "#             lr = self.lr\n",
    "            \n",
    "#         tf.compat.v1.logging.info(\"Starting Training\")\n",
    "\n",
    "#         @tf.function\n",
    "#         def train_step(inputs, labels, weights):\n",
    "#             with tf.GradientTape() as tape:\n",
    "#                 logits = self.model(inputs, training=True)\n",
    "#                 kl_loss = sum(self.model.losses)\n",
    "#                 neg_log_likelihood = self.loss_fn(labels, logits, weights)\n",
    "#                 elbo_loss = neg_log_likelihood + kl_loss\n",
    "            \n",
    "#             gradients = tape.gradient(elbo_loss, self.model.trainable_variables)\n",
    "#             self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "\n",
    "#             return elbo_loss, neg_log_likelihood, kl_loss\n",
    "\n",
    "#         for step, (inputs, labels, weights) in enumerate(self.train_iter.take(num_steps)): \n",
    "\n",
    "#             loss = train_step(inputs, labels, weights)\n",
    "\n",
    "#             if step % 1000 == 0:\n",
    "#                 tf.compat.v1.logging.info(str(step) + \" \" + str(tf.reduce_mean(loss[0])) + \n",
    "#                                           str(tf.reduce_mean(loss[1])) +\n",
    "#                                           str(tf.reduce_mean(loss[2])))\n",
    "                \n",
    "#                 if (self.debug):\n",
    "#                     tf.compat.v1.logging.info(\"On validation\")\n",
    "#                     _, _, _, _, _ = self.test(40000, log=False)\n",
    "#                     tf.compat.v1.logging.info(\"\")\n",
    "\n",
    "#     def test(self, num_samples, mode = Dataset.VALID, log=False):\n",
    "#         \"\"\"\n",
    "#         Tests model on valid and test dataset handlers.\n",
    "#         \"\"\"\n",
    "\n",
    "#         if (mode == Dataset.VALID):\n",
    "#             handle = self.valid_iter # for standard validation of validation cell types\n",
    "            \n",
    "#         elif (mode == Dataset.TEST and len(self.test_celltypes) > 0):\n",
    "#             handle = self.test_iter # for standard validation of validation cell types        \n",
    "#         else:\n",
    "#             raise Exception(\"No data exists for %s. Use function test_from_generator() if you want to create a new iterator.\" % (mode))\n",
    "            \n",
    "#         return self.run_predictions(num_samples, handle, log)      \n",
    "        \n",
    "#     def test_from_generator(self, num_samples, ds, log=False):\n",
    "#         \"\"\"\n",
    "#         Runs test given a specified data generator \n",
    "#         :param num_samples: number of samples to test\n",
    "#         :param ds: tensorflow dataset, created by dataset_to_tf_dataset\n",
    "#         :param cell_type: cell type to test on. Used to generate holdout indices.\n",
    "        \n",
    "#         :return predictions\n",
    "#         \"\"\"\n",
    "#         return self.run_predictions(num_samples, ds, log)\n",
    "    \n",
    "#     def eval_vector(self, data, vector, indices):\n",
    "#         \"\"\"\n",
    "#         Evaluates a new cell type based on its chromatin (DNase or ATAC-seq) vector. len(vector) should equal\n",
    "#         the data.shape[1]\n",
    "#         :param data: data to build features from \n",
    "#         :param vector: vector of 0s/1s of binding sites TODO AM 4/3/2019: try peak strength instead of 0s/1s\n",
    "#         :param indices: indices of vector to actually score. You need all of the locations for the generator.\n",
    "\n",
    "#         :return predictions for all factors\n",
    "#         \"\"\"\n",
    "        \n",
    "#         _,  ds = generator_to_tf_dataset(load_data(data, \n",
    "#                  self.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "#                  self.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "#                  self.matrix,\n",
    "#                  self.assaymap,\n",
    "#                  self.cellmap,\n",
    "#                  radii = self.radii,\n",
    "#                  mode = Dataset.RUNTIME,\n",
    "#                  dnase_vector = vector, indices = indices), self.batch_size, 1, self.prefetch_size)\n",
    "\n",
    "#         num_samples = len(indices)\n",
    "        \n",
    "#         preds, _, _, _, _ = self.run_predictions(num_samples, ds, False, calculate_metrics = False)    \n",
    "        \n",
    "#         return preds\n",
    "\n",
    "#     def run_predictions(self, num_samples, iter_, log, calculate_metrics = True, samples = 500):\n",
    "#         \"\"\"\n",
    "#         Runs predictions on num_samples records\n",
    "#         :param num_samples: number of samples to test\n",
    "#         :param iter_: output of self.sess.run(generator_to_one_shot_iterator()), handle to one shot iterator of records\n",
    "#         :param log: if true, logs individual factor accuracies\n",
    "        \n",
    "#         :return preds, truth, assay_dict, auROC, auPRC, False\n",
    "#             preds = predictions, \n",
    "#             truth = actual values, \n",
    "#             sample_weight: 0/1 weights on predictions.  \n",
    "#             assay_dict = if log=True, holds predictions for individual factors\n",
    "#             auROC = average macro area under ROC for all factors with truth values\n",
    "#             auPRC = average area under PRC for all factors with truth values\n",
    "#         \"\"\"\n",
    "        \n",
    "#         inv_assaymap = {v: k for k, v in self.assaymap.items()}\n",
    "                        \n",
    "#         # batches of predictions\n",
    "#         vals = []\n",
    "\n",
    "#         # Calculate epistemic uncertainty by iterating over a certain number of times,\n",
    "#         # getting y_preds. You can then calculate the mean and sigma of the predictions, \n",
    "#         # and use this to gather uncertainty: (see http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)\n",
    "#         # inputs, truth, sample_weight\n",
    "#         vals = [(i[0],i[1],i[2]) for i in iter_.take(int(num_samples / self.batch_size)+1)]\n",
    "        \n",
    "#         inputs = np.concatenate([v[0] for v in vals])[:num_samples]\n",
    "#         truth = np.concatenate([v[1] for v in vals])[:num_samples]\n",
    "#         sample_weight = np.concatenate([v[2] for v in vals])[:num_samples]\n",
    "    \n",
    "#         y_pred_list = []\n",
    "#         for i in tqdm.tqdm(range(samples)):\n",
    "            \n",
    "#             y_pred = tf.sigmoid(self.model(inputs, training=False))\n",
    "#             y_pred = y_pred[:,Features.FEATURE_IDX.value,:] # get feature row\n",
    "#             y_pred_list.append(y_pred)\n",
    "            \n",
    "#         preds = np.dstack(y_pred_list)\n",
    "\n",
    "#         preds_mean = np.mean(preds, axis=2)\n",
    "#         preds_sigma = np.std(preds, axis=2)\n",
    "        \n",
    "#         # reset truth back to 0 to compute metrics\n",
    "#         # sample weights will rule these out anyways when computing metrics\n",
    "#         truth_reset = np.copy(truth)\n",
    "#         truth_reset[truth_reset < Label.UNBOUND.value] = 0 \n",
    "                                           \n",
    "#         # do not continue to calculate metrics. Just return predictions and true values\n",
    "#         if (not calculate_metrics):\n",
    "#             return preds_mean, preds_sigma, truth, sample_weight, None, None, None\n",
    "        \n",
    "#         assert(preds_mean.shape == sample_weight.shape)\n",
    "        \n",
    "\n",
    "#         try:\n",
    "#             # Mean results because sample_weight mask can only work on 1 row at a time.\n",
    "#             # If a given assay is not available for evaluation, sample_weights will all be 0 \n",
    "#             # and the resulting roc_auc_score will be NaN.\n",
    "#             auROC_vec = []\n",
    "#             auPRC_vec = []\n",
    "#             GINI_vec =  []\n",
    "\n",
    "\n",
    "#             # try/accept for cases with only one class (throws ValueError)\n",
    "#             assay_dict = {}\n",
    "\n",
    "#             for j in range(preds.shape[1]): # for all assays\n",
    "#                 assay = inv_assaymap[j+1] \n",
    "\n",
    "#                 roc_score = np.NAN\n",
    "\n",
    "#                 try:\n",
    "#                     roc_score = sklearn.metrics.roc_auc_score(truth[:,j], preds_mean[:,j], \n",
    "#                                                       average='macro', \n",
    "#                                                       sample_weight = sample_weight[:,j])\n",
    "\n",
    "#                     auROC_vec.append(roc_score)\n",
    "\n",
    "#                 except ValueError:\n",
    "#                     roc_score = np.NaN\n",
    "\n",
    "#                 try:\n",
    "#                     pr_score = sklearn.metrics.average_precision_score(truth[:,j], preds_mean[:,j], \n",
    "#                                                              sample_weight = sample_weight[:, j])\n",
    "\n",
    "#                     auPRC_vec.append(pr_score)\n",
    "\n",
    "#                 except ValueError:\n",
    "#                     pr_score = np.NaN\n",
    "\n",
    "#                 try:\n",
    "#                     gini_score = self.gini_normalized(truth[:,j], preds_mean[:,j], \n",
    "#                                                       sample_weight = sample_weight[:, j])\n",
    "\n",
    "#                     GINI_vec.append(gini_score)\n",
    "\n",
    "#                 except ValueError:\n",
    "#                     gini_score = np.NaN\n",
    "\n",
    "#                 assay_dict[assay] = {\"AUC\": roc_score, \"auPRC\": pr_score, \"GINI\": gini_score }\n",
    "\n",
    "\n",
    "#             auROC = np.nanmean(auROC_vec)\n",
    "#             auPRC = np.nanmean(auPRC_vec)\n",
    "\n",
    "#             tf.compat.v1.logging.info(\"macro auROC:     \" + str(auROC))\n",
    "#             tf.compat.v1.logging.info(\"auPRC:     \" + str(auPRC))\n",
    "#             tf.compat.v1.logging.info(\"GINI:     \" + str(np.nanmean(GINI_vec)))\n",
    "#         except ValueError as v:\n",
    "#             auROC = None\n",
    "#             auPRC = None\n",
    "#             tf.compat.v1.logging.info(\"Failed to calculate metrics\")\n",
    "\n",
    "#         return preds_mean, preds_sigma, truth, sample_weight, assay_dict, auROC, auPRC\n",
    "        \n",
    "#     def score_peak_file(self, peak_file):\n",
    "    \n",
    "#         # get peak_vector, which is a vector matching train set. Some peaks will not overlap train set, \n",
    "#         # and their indices are stored in missing_idx for future use\n",
    "#         peak_vector, all_peaks = bedFile2Vector(peak_file)\n",
    "#         print(\"finished loading peak file\")\n",
    "\n",
    "#         # only select peaks to score\n",
    "#         idx = np.where(peak_vector == 1)[0]\n",
    "        \n",
    "#         if len(idx) == 0:\n",
    "#             raise ValueError(\"No positive peaks found in %s\" % peak_file)\n",
    "\n",
    "#         all_data = np.concatenate((self.data[Dataset.TRAIN], self.data[Dataset.VALID], self.data[Dataset.TEST]), axis=1)\n",
    "\n",
    "#         # takes about 1.5 minutes for 100,000 regions TODO AM 4/3/2019 speed up generator\n",
    "#         predictions = self.eval_vector(all_data, peak_vector, idx)\n",
    "#         print(\"finished predictions...\", predictions.shape)\n",
    "\n",
    "\n",
    "#         # get number of factors to fill in if values are missing\n",
    "#         num_factors = predictions[0].shape[0]\n",
    "\n",
    "#         # map predictions with genomic position \n",
    "#         liRegions = load_allpos_regions()\n",
    "#         prediction_positions = itemgetter(*idx)(liRegions)\n",
    "#         zipped = list(zip(prediction_positions, predictions))\n",
    "\n",
    "#         # for each all_peaks, if 1, reduce means for all overlapping peaks in positions\n",
    "#         # else, set to 0s\n",
    "\n",
    "#         def reduceMeans(peak):\n",
    "#             if (peak[1] == 1):\n",
    "#                 # parse region\n",
    "\n",
    "#                 # filter overlapping predictions for this peak and take mean      \n",
    "#                 res = map(lambda k: k[1], filter(lambda x: peak[0].overlaps(x[0], 100), zipped))\n",
    "#                 arr = np.concatenate(list(map(lambda x: np.matrix(x), res)), axis = 0)\n",
    "#                 return(peak[0], np.mean(arr, axis = 0))\n",
    "#             else:\n",
    "#                 return(peak[0], np.zeros(num_factors)) \n",
    "\n",
    "#         grouped = list(map(lambda x: np.matrix(reduceMeans(x)[1]), all_peaks))\n",
    "\n",
    "#         final = np.concatenate(grouped, axis=0)\n",
    "\n",
    "#         df = pd.DataFrame(final, columns=list(self.assaymap)[1:])\n",
    "\n",
    "#         # load in peaks to get positions and could be called only once\n",
    "#         # TODO why are you reading this in twice?\n",
    "#         df_pos = pd.read_csv(peak_file, sep=\"\\t\", header = None)[[0,1,2]]\n",
    "#         final_df = pd.concat([df_pos, df], axis=1)\n",
    "\n",
    "#         return final_df\n",
    "            \n",
    "\n",
    "# class VLP(VariationalPeakModel):\n",
    "#     def __init__(self,\n",
    "#              *args,\n",
    "#              **kwargs):\n",
    "\n",
    "#         \"\"\" To resume model training, call:\n",
    "#             model2 = MLP(data = data, checkpoint=\"/home/eecs/akmorrow/epitome/out/models/test_model\")\n",
    "#         \"\"\"\n",
    "#         self.layers = 4\n",
    "#         self.num_units = [100, 100, 100, 50]\n",
    "#         self.activation = tf.tanh\n",
    "                          \n",
    "#         if \"checkpoint\" in kwargs.keys():\n",
    "#             fileObject = open(kwargs[\"checkpoint\"] + \"/model_params.pickle\" ,'rb')\n",
    "#             metadata = pickle.load(fileObject)\n",
    "#             PeakModel.__init__(self, kwargs[\"data\"], **metadata)\n",
    "#             self.training_size = kwargs[\"data\"][Dataset.TRAIN].shape[1]\n",
    "#             self.model = tf.keras.models.load_model(kwargs[\"checkpoint\"])\n",
    "            \n",
    "#         else: \n",
    "#             self.training_size =( args[0][Dataset.TRAIN]).shape[1]\n",
    "#             PeakModel.__init__(self, *args, **kwargs)\n",
    "            \n",
    "#     def create_model(self):\n",
    "        \n",
    "#         model = tf.keras.Sequential()\n",
    "\n",
    "#         if not isinstance(self.num_units, collections.Iterable):\n",
    "#             self.num_units = [self.num_units] * self.layers\n",
    "#         for i in range(self.layers):\n",
    "#             model.add(tfp.layers.DenseFlipout(self.num_units[i], activation = self.activation))\n",
    "\n",
    "#         # output layer\n",
    "#         model.add(tfp.layers.DenseFlipout(self.num_outputs,\n",
    "#                                           activity_regularizer=tf.keras.regularizers.l1_l2(self.l1, self.l2)))\n",
    "        \n",
    "#         return model\n",
    "\n",
    "# mlp_model = VLP(data,\n",
    "#         [],\n",
    "#         matrix,\n",
    "#         assaymap,\n",
    "#         cellmap,\n",
    "#         shuffle_size=2, \n",
    "#         batch_size=64)\n",
    "\n",
    "# mlp_model.train(10)\n",
    "\n",
    "# results = mlp_model.test(10)\n",
    "# results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0729 16:45:23.222460 139858324326144 models.py:625] Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval cell types ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HUVEC', 'HCT-116', 'H1-hESC', 'GM12892', 'GM12891', 'GM12878', 'A549']\n",
      "using ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HUVEC', 'HCT-116', 'H1-hESC', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HUVEC', 'HCT-116', 'H1-hESC', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "using [] as labels for mode Dataset.TEST\n",
      "Error: no data, local variable 'x' referenced before assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0729 16:45:23.583067 139858324326144 deprecation.py:323] From /data/miniconda3/envs/EpitomeEnv_c76/lib/python3.7/site-packages/tensorflow_probability/python/layers/util.py:103: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "W0729 16:45:24.904508 139858324326144 deprecation.py:323] From /data/miniconda3/envs/EpitomeEnv_c76/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0729 16:45:25.798658 139858324326144 deprecation.py:323] From /data/miniconda3/envs/EpitomeEnv_c76/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:468: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n",
      "I0729 16:45:27.183236 139858324326144 models.py:647] 0 tf.Tensor(0.051145982, shape=(), dtype=float32)tf.Tensor(0.051145982, shape=(), dtype=float32)tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "100%|| 500/500 [00:16<00:00, 30.51it/s]\n",
      "I0729 16:45:44.364020 139858324326144 models.py:813] macro auROC:     nan\n",
      "I0729 16:45:44.364998 139858324326144 models.py:814] auPRC:     nan\n",
      "I0729 16:45:44.365984 139858324326144 models.py:815] GINI:     nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.35937378, 0.21215467, 0.21174686, 0.3151953 , 0.24296808,\n",
       "         0.26103526, 0.16899301, 0.16687271, 0.41734293, 0.4730879 ,\n",
       "         0.38635656, 0.1661213 , 0.41452068],\n",
       "        [0.3702349 , 0.20541921, 0.19921516, 0.31112316, 0.23689203,\n",
       "         0.2553056 , 0.18114923, 0.16065891, 0.41471753, 0.47716436,\n",
       "         0.38902196, 0.16064976, 0.4226988 ],\n",
       "        [0.35753205, 0.21173602, 0.20962557, 0.31398284, 0.24243735,\n",
       "         0.26107836, 0.17402853, 0.16307329, 0.41702232, 0.46760678,\n",
       "         0.38444883, 0.16335602, 0.4107344 ],\n",
       "        [0.365708  , 0.21282157, 0.20044132, 0.31236738, 0.24034575,\n",
       "         0.25332758, 0.17989194, 0.16563748, 0.4173311 , 0.4951811 ,\n",
       "         0.37528795, 0.1577859 , 0.4188522 ],\n",
       "        [0.35858497, 0.2067922 , 0.20905861, 0.30024385, 0.23663574,\n",
       "         0.26068076, 0.18157175, 0.16407678, 0.42018   , 0.46826124,\n",
       "         0.38602474, 0.16057971, 0.4172198 ],\n",
       "        [0.35268477, 0.21015033, 0.20939459, 0.31091768, 0.24142823,\n",
       "         0.25372356, 0.17328466, 0.16071703, 0.42049572, 0.47004035,\n",
       "         0.3824898 , 0.16421597, 0.4167075 ],\n",
       "        [0.3544451 , 0.2075137 , 0.20396775, 0.31586432, 0.24314067,\n",
       "         0.2594031 , 0.17577542, 0.16544862, 0.41860232, 0.46995905,\n",
       "         0.38376403, 0.1611723 , 0.4206331 ],\n",
       "        [0.36327678, 0.21439146, 0.19743425, 0.3127858 , 0.23858461,\n",
       "         0.25640902, 0.18035923, 0.17061557, 0.42106938, 0.49355143,\n",
       "         0.38093808, 0.15824293, 0.42107388],\n",
       "        [0.36236158, 0.2136381 , 0.199252  , 0.3118121 , 0.24297644,\n",
       "         0.25810656, 0.18093552, 0.17077072, 0.41622844, 0.49094075,\n",
       "         0.3793881 , 0.15992925, 0.42162618],\n",
       "        [0.36220074, 0.21808144, 0.20257318, 0.31296587, 0.24052206,\n",
       "         0.25998414, 0.1807237 , 0.16818601, 0.42269665, 0.48949054,\n",
       "         0.38228008, 0.16000551, 0.42283383]], dtype=float32),\n",
       " array([[0.06397394, 0.05174354, 0.05271744, 0.05952067, 0.05301338,\n",
       "         0.06130782, 0.04167436, 0.04048883, 0.06553636, 0.06725141,\n",
       "         0.06767498, 0.04063356, 0.06925767],\n",
       "        [0.06568893, 0.04685572, 0.05184555, 0.06097155, 0.05012345,\n",
       "         0.05892418, 0.04350203, 0.03963993, 0.06363285, 0.0736662 ,\n",
       "         0.07191683, 0.03833337, 0.07093032],\n",
       "        [0.06115881, 0.04807704, 0.05517102, 0.06012417, 0.05484958,\n",
       "         0.06083306, 0.04353676, 0.04179394, 0.06272552, 0.0751555 ,\n",
       "         0.06832927, 0.03775397, 0.07060447],\n",
       "        [0.06767209, 0.04979751, 0.04880797, 0.05859403, 0.05017326,\n",
       "         0.05819571, 0.04437516, 0.04014101, 0.0643853 , 0.0695345 ,\n",
       "         0.06563014, 0.0360508 , 0.06593901],\n",
       "        [0.06766888, 0.0467719 , 0.04999364, 0.05879459, 0.05141461,\n",
       "         0.05677209, 0.04787987, 0.04199942, 0.06669359, 0.07313066,\n",
       "         0.06811994, 0.0400751 , 0.06810451],\n",
       "        [0.06316986, 0.04869378, 0.05292835, 0.06522163, 0.05261315,\n",
       "         0.05644625, 0.04360155, 0.03799656, 0.06540343, 0.07108471,\n",
       "         0.06989943, 0.03858365, 0.06766818],\n",
       "        [0.06491941, 0.0478633 , 0.05394497, 0.0597533 , 0.05511156,\n",
       "         0.05974266, 0.04030867, 0.0408875 , 0.06454714, 0.07627696,\n",
       "         0.06964391, 0.03868436, 0.06597618],\n",
       "        [0.06422512, 0.04688105, 0.05084021, 0.06157085, 0.05158306,\n",
       "         0.05839443, 0.04272857, 0.04415183, 0.06722417, 0.07416356,\n",
       "         0.06938419, 0.03751595, 0.06930151],\n",
       "        [0.06343966, 0.04621711, 0.05210812, 0.05994183, 0.05110736,\n",
       "         0.05538384, 0.04518659, 0.04399567, 0.06577942, 0.07467506,\n",
       "         0.06769109, 0.03802128, 0.07107327],\n",
       "        [0.06618075, 0.05387884, 0.04728665, 0.06059382, 0.05256722,\n",
       "         0.05964328, 0.04659871, 0.04452875, 0.06386541, 0.07356171,\n",
       "         0.06877995, 0.03853906, 0.06742866]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32),\n",
       " array([[0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "       dtype=float32),\n",
       " {'p300': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'c-Myc': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'YY1': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'TAF1': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'Rad21': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'Pol2-4H8': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'Pol2': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'NRSF': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'Max': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'GABP': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'EZH2': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'CTCF': {'AUC': nan, 'auPRC': nan, 'GINI': nan},\n",
       "  'CEBPB': {'AUC': nan, 'auPRC': nan, 'GINI': nan}},\n",
       " nan,\n",
       " nan)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = VLP(data,\n",
    "        [],\n",
    "        matrix,\n",
    "        assaymap,\n",
    "        cellmap,\n",
    "        shuffle_size=2, \n",
    "        batch_size=64)\n",
    "\n",
    "mlp_model.train(10)\n",
    "\n",
    "results = mlp_model.test(10)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS ON JUST CTCF (3000 iters)\n",
    "\n",
    "\n",
    "## new model(Flipout)\n",
    "- macro auROC:     0.9779000096968956\n",
    "- auPRC:     0.8028331881979279\n",
    "- GINI:     0.9558000193937909\n",
    "\n",
    "## original model\n",
    "- loss is 70 - ...58\n",
    "- 'AUC': 0.9827358578435126\n",
    "-  'auPRC': 0.8306948625675733\n",
    "- 'GINI': 0.9654720346638495\n",
    "- variance is negligible (5e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeEnv_c76",
   "language": "python",
   "name": "epitomeenv_c76"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
